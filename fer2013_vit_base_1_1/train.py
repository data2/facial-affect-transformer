import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import DataLoader, WeightedRandomSampler
from torchvision import transforms, datasets
import timm
from sklearn.metrics import confusion_matrix, classification_report
import numpy as np
from PIL import Image
from tqdm import tqdm
import time
import os
import math
from sklearn.utils.class_weight import compute_class_weight


# === é«˜çº§ä¼˜åŒ–ç»„ä»¶ ===
class EarlyStopping:
    def __init__(self, patience=10, delta=0.001, min_epochs=20):
        self.patience = patience
        self.delta = delta
        self.min_epochs = min_epochs
        self.best_acc = 0
        self.counter = 0
        self.early_stop = False

    def __call__(self, val_acc, epoch):
        if epoch < self.min_epochs:
            return False
            
        if val_acc > self.best_acc + self.delta:
            self.best_acc = val_acc
            self.counter = 0
        else:
            self.counter += 1
            if self.counter >= self.patience:
                self.early_stop = True
        return self.early_stop


class LabelSmoothingCrossEntropy(nn.Module):
    """æ ‡ç­¾å¹³æ»‘æŸå¤±å‡½æ•°"""
    def __init__(self, smoothing=0.1):
        super().__init__()
        self.smoothing = smoothing

    def forward(self, x, target):
        confidence = 1.0 - self.smoothing
        logprobs = F.log_softmax(x, dim=-1)
        nll_loss = -logprobs.gather(dim=-1, index=target.unsqueeze(1))
        nll_loss = nll_loss.squeeze(1)
        smooth_loss = -logprobs.mean(dim=-1)
        loss = confidence * nll_loss + self.smoothing * smooth_loss
        return loss.mean()


class FocalLoss(nn.Module):
    """Focal Lossç”¨äºå¤„ç†ç±»åˆ«ä¸å‡è¡¡"""
    def __init__(self, alpha=1, gamma=2, reduction='mean'):
        super().__init__()
        self.alpha = alpha
        self.gamma = gamma
        self.reduction = reduction

    def forward(self, inputs, targets):
        ce_loss = F.cross_entropy(inputs, targets, reduction='none')
        pt = torch.exp(-ce_loss)
        focal_loss = self.alpha * (1 - pt) ** self.gamma * ce_loss
        
        if self.reduction == 'mean':
            return focal_loss.mean()
        elif self.reduction == 'sum':
            return focal_loss.sum()
        else:
            return focal_loss


def cutmix_data(x, y, alpha=1.0):
    """CutMixæ•°æ®å¢å¼º"""
    if alpha <= 0:
        return x, y, y, 1.0
        
    # ç”Ÿæˆlambdaå€¼
    lam = np.random.beta(alpha, alpha)
    
    batch_size = x.size()[0]
    index = torch.randperm(batch_size).to(x.device)
    
    # ç”Ÿæˆè£å‰ªåŒºåŸŸ
    bbx1, bby1, bbx2, bby2 = rand_bbox(x.size(), lam)
    x[:, :, bbx1:bbx2, bby1:bby2] = x[index, :, bbx1:bbx2, bby1:bby2]
    
    # è°ƒæ•´lambda
    lam = 1 - ((bbx2 - bbx1) * (bby2 - bby1) / (x.size()[-1] * x.size()[-2]))
    y_a, y_b = y, y[index]
    
    return x, y_a, y_b, lam


def rand_bbox(size, lam):
    """ç”Ÿæˆéšæœºè£å‰ªåŒºåŸŸ"""
    W = size[2]
    H = size[3]
    cut_rat = np.sqrt(1. - lam)
    cut_w = int(W * cut_rat)
    cut_h = int(H * cut_rat)

    # å‡åŒ€åˆ†å¸ƒ
    cx = np.random.randint(W)
    cy = np.random.randint(H)

    bbx1 = np.clip(cx - cut_w // 2, 0, W)
    bby1 = np.clip(cy - cut_h // 2, 0, H)
    bbx2 = np.clip(cx + cut_w // 2, 0, W)
    bby2 = np.clip(cy + cut_h // 2, 0, H)

    return bbx1, bby1, bbx2, bby2


def cutmix_criterion(criterion, pred, y_a, y_b, lam):
    """CutMixæŸå¤±å‡½æ•°"""
    return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)


def mixup_data(x, y, alpha=0.2):
    """MixUpæ•°æ®å¢å¼º"""
    if alpha > 0:
        lam = np.random.beta(alpha, alpha)
    else:
        lam = 1
    
    batch_size = x.size()[0]
    index = torch.randperm(batch_size).to(x.device)
    
    mixed_x = lam * x + (1 - lam) * x[index]
    y_a, y_b = y, y[index]
    return mixed_x, y_a, y_b, lam


def mixup_criterion(criterion, pred, y_a, y_b, lam):
    """MixUpæŸå¤±å‡½æ•°"""
    return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)


def get_cosine_schedule_with_warmup(optimizer, num_warmup_steps, num_training_steps, num_cycles=0.5):
    """å¸¦çƒ­èº«çš„ä½™å¼¦é€€ç«è°ƒåº¦å™¨"""
    def lr_lambda(current_step):
        if current_step < num_warmup_steps:
            return float(current_step) / float(max(1, num_warmup_steps))
        progress = float(current_step - num_warmup_steps) / float(max(1, num_training_steps - num_warmup_steps))
        return max(0.0, 0.5 * (1.0 + math.cos(math.pi * float(num_cycles) * 2.0 * progress)))
    
    return torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda)


class AdaptiveDataAugmentation:
    """è‡ªé€‚åº”æ•°æ®å¢å¼º"""
    def __init__(self, cutmix_prob=0.5, mixup_prob=0.3):
        self.cutmix_prob = cutmix_prob
        self.mixup_prob = mixup_prob
        self.epoch = 0
        
    def update_probabilities(self, class_accuracies):
        """æ ¹æ®ç±»åˆ«å‡†ç¡®ç‡åŠ¨æ€è°ƒæ•´å¢å¼ºæ¦‚ç‡"""
        # å¦‚æœdisgustæˆ–fearå‡†ç¡®ç‡ä½ï¼Œå¢åŠ å¢å¼ºæ¦‚ç‡
        disgust_acc = class_accuracies[1] if len(class_accuracies) > 1 else 0
        fear_acc = class_accuracies[2] if len(class_accuracies) > 2 else 0
        
        if disgust_acc < 0.1 or fear_acc < 0.3:
            self.cutmix_prob = min(0.7, self.cutmix_prob + 0.1)
            self.mixup_prob = min(0.5, self.mixup_prob + 0.1)
        else:
            self.cutmix_prob = 0.5
            self.mixup_prob = 0.3
            
    def apply_augmentation(self, images, labels, epoch):
        """åº”ç”¨è‡ªé€‚åº”å¢å¼º"""
        self.epoch = epoch
        
        # 30%æ¦‚ç‡ä½¿ç”¨CutMix
        if np.random.rand() < self.cutmix_prob:
            images, targets_a, targets_b, lam = cutmix_data(images, labels, alpha=1.0)
            return images, targets_a, targets_b, lam, 'cutmix'
        
        # 20%æ¦‚ç‡ä½¿ç”¨MixUp
        elif np.random.rand() < self.mixup_prob:
            images, targets_a, targets_b, lam = mixup_data(images, labels, alpha=0.2)
            return images, targets_a, targets_b, lam, 'mixup'
        
        # 50%æ¦‚ç‡ä¸ä½¿ç”¨å¢å¼º
        else:
            return images, labels, labels, 1.0, 'none'


def main():
    print("å¼€å§‹è¿›å…¥è®­ç»ƒ - è‡ªé€‚åº”ä¼˜åŒ–ç‰ˆæœ¬ (ç›®æ ‡: 80%å‡†ç¡®ç‡)")
    print("=" * 60)

    # === è®¾å¤‡è®¾ç½® ===
    if torch.cuda.is_available():
        device = torch.device('cuda')
        print(f"âœ… ä½¿ç”¨GPU: {torch.cuda.get_device_name()}")
        print(f"ğŸ’¾ æ˜¾å­˜: {torch.cuda.get_device_properties(0).total_memory / 1024 ** 3:.1f} GB")
        torch.cuda.empty_cache()
    else:
        device = torch.device('cpu')
        print("âš ï¸ æœªå‘ç°GPUï¼Œä½¿ç”¨CPU")

    # === è¶…å‚æ•°é…ç½® ===
    config = {
        'model_size': 'base',
        'batch_size': 16,
        'num_epochs': 100,
        'learning_rate': 2e-5,  # å½“å‰å­¦ä¹ ç‡
        'weight_decay': 0.05,
        'cutmix_alpha': 1.0,
        'label_smoothing': 0.1,
        'drop_rate': 0.2,
        'grad_accum_steps': 2,
        'warmup_epochs': 10,
        'current_epoch': 4,  # å½“å‰è®­ç»ƒåˆ°ç¬¬4ä¸ªepoch
    }
    
    MODEL_SIZE = config['model_size']
    print(f"ğŸ¯ ç›®æ ‡: 80%éªŒè¯å‡†ç¡®ç‡ | æ¨¡å‹: ViT-{MODEL_SIZE.capitalize()}")

    # === 1. è‡ªé€‚åº”æ•°æ®é¢„å¤„ç† ===
    print("\nğŸ”„ é…ç½®è‡ªé€‚åº”æ•°æ®å¢å¼º...")
    
    def strong_disgust_augmentation(image):
        """é’ˆå¯¹disgustç±»åˆ«çš„å¼ºå¢å¼º"""
        # æç«¯é¢œè‰²å˜æ¢
        image = transforms.functional.adjust_hue(image, 0.3)
        image = transforms.functional.adjust_saturation(image, 3.0)
        image = transforms.functional.adjust_contrast(image, 2.0)
        image = transforms.functional.adjust_sharpness(image, 2.0)
        return image

    def fear_specific_augmentation(image):
        """é’ˆå¯¹fearç±»åˆ«çš„å¢å¼º"""
        image = transforms.functional.adjust_brightness(image, 1.3)
        image = transforms.functional.adjust_contrast(image, 1.5)
        return image

    class AdaptiveTransform:
        """è‡ªé€‚åº”å˜æ¢ï¼Œæ ¹æ®ç±»åˆ«åº”ç”¨ä¸åŒå¢å¼º"""
        def __init__(self, base_transform):
            self.base_transform = base_transform
            
        def __call__(self, img, label=None):
            img = self.base_transform(img)
            
            # å¦‚æœæä¾›äº†æ ‡ç­¾ï¼Œåº”ç”¨ç±»åˆ«ç‰¹å®šå¢å¼º
            if label is not None:
                if label == 1:  # disgust
                    img = strong_disgust_augmentation(img)
                elif label == 2:  # fear
                    img = fear_specific_augmentation(img)
                    
            return img

    # è®­ç»ƒæ—¶ä½¿ç”¨çš„å¢å¼ºtransform
    train_transform = transforms.Compose([
        transforms.Resize((256, 256)),
        transforms.RandomCrop((224, 224)),
        transforms.Grayscale(num_output_channels=3),
        
        # ç©ºé—´å˜æ¢
        transforms.RandomHorizontalFlip(p=0.5),
        transforms.RandomRotation(degrees=15),
        transforms.RandomAffine(degrees=10, translate=(0.1, 0.1), scale=(0.9, 1.1)),
        
        # é¢œè‰²å˜æ¢
        transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.3, hue=0.1),
        transforms.GaussianBlur(kernel_size=7, sigma=(0.1, 3.0)),
        
        # è½¬æ¢ä¸ºtensor
        transforms.ToTensor(),
        
        # å½’ä¸€åŒ–
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
        
        # tensorä¸Šçš„å˜æ¢
        transforms.RandomErasing(p=0.4, scale=(0.02, 0.2), ratio=(0.3, 3.3)),
    ])

    # éªŒè¯é›†transform
    val_transform = transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.Grayscale(num_output_channels=3),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    ])

    # ç®€å•transformç”¨äºè·å–æ ‡ç­¾
    simple_transform = transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.Grayscale(num_output_channels=3),
        transforms.ToTensor(),
    ])

    # === 2. åŠ è½½æ•°æ®é›† ===
    print("ğŸ“ åŠ è½½æ•°æ®é›†...")
    train_dir = './data/train'
    test_dir = './data/test'

    if not os.path.exists(train_dir):
        raise FileNotFoundError(f"âŒ è®­ç»ƒæ•°æ®è·¯å¾„ä¸å­˜åœ¨: {train_dir}")
    if not os.path.exists(test_dir):
        raise FileNotFoundError(f"âŒ æµ‹è¯•æ•°æ®è·¯å¾„ä¸å­˜åœ¨: {test_dir}")

    train_dataset_simple = datasets.ImageFolder(train_dir, transform=simple_transform)
    train_dataset = datasets.ImageFolder(train_dir, transform=train_transform)
    val_dataset = datasets.ImageFolder(test_dir, transform=val_transform)

    # è·å–è®­ç»ƒæ ‡ç­¾
    train_labels = [label for _, label in train_dataset_simple]

    print(f"ğŸ“Š æ•°æ®ç»Ÿè®¡:")
    print(f"  è®­ç»ƒæ ·æœ¬: {len(train_dataset)}")
    print(f"  éªŒè¯æ ·æœ¬: {len(val_dataset)}")
    print(f"  ç±»åˆ«æ•°é‡: {len(train_dataset.classes)}")
    print(f"  ç±»åˆ«åç§°: {train_dataset.classes}")

    # === 3. è‡ªé€‚åº”é‡‡æ ·ç­–ç•¥ ===
    def get_adaptive_sampler(dataset, class_accuracies=None):
        """æ ¹æ®ç±»åˆ«å‡†ç¡®ç‡è°ƒæ•´é‡‡æ ·æƒé‡"""
        # è®¡ç®—æ¯ä¸ªç±»åˆ«çš„æ ·æœ¬æ•°
        class_counts = np.bincount(train_labels)
        class_weights = 1. / torch.tensor(class_counts, dtype=torch.float)
        
        # å¦‚æœæä¾›äº†ç±»åˆ«å‡†ç¡®ç‡ï¼Œè°ƒæ•´æƒé‡
        if class_accuracies is not None:
            for i, acc in enumerate(class_accuracies):
                if acc < 0.3:  # å‡†ç¡®ç‡ä½çš„ç±»åˆ«å¢åŠ æƒé‡
                    class_weights[i] *= 5.0
                elif acc < 0.5:
                    class_weights[i] *= 2.0
        
        sample_weights = [class_weights[label] for _, label in dataset]
        sampler = WeightedRandomSampler(sample_weights, len(sample_weights))
        return sampler

    # æ•°æ®åŠ è½½å™¨
    num_workers = min(8, os.cpu_count())
    train_loader = DataLoader(train_dataset, batch_size=config['batch_size'], shuffle=True,
                              num_workers=num_workers, pin_memory=True, drop_last=True)
    val_loader = DataLoader(val_dataset, batch_size=config['batch_size'], shuffle=False,
                            num_workers=num_workers, pin_memory=True)

    print(f"  Batch Size: {config['batch_size']} (ç´¯ç§¯æ­¥æ•°: {config['grad_accum_steps']})")

    # === 4. åŠ¨æ€ç±»åˆ«æƒé‡ ===
    class_weights = compute_class_weight('balanced', classes=np.unique(train_labels), y=train_labels)
    class_weights = torch.tensor(class_weights, dtype=torch.float32).to(device)
    
    # åŸºäºç¬¬4ä¸ªepochç»“æœè°ƒæ•´æƒé‡
    current_class_acc = [0.646, 0.072, 0.363, 0.928, 0.727, 0.525, 0.746]  # ç¬¬4ä¸ªepochç»“æœ
    
    # åŠ¨æ€è°ƒæ•´æƒé‡
    class_weights[1] *= 8.0  # disgust: å¤§å¹…å¢åŠ æƒé‡ (ä»7.2%å‡†ç¡®ç‡)
    class_weights[2] *= 3.0  # fear: å¢åŠ æƒé‡ (ä»36.3%å‡†ç¡®ç‡)
    class_weights[5] *= 1.5  # sad: è½»å¾®å¢åŠ æƒé‡ (ä»52.5%å‡†ç¡®ç‡)
    
    print("ğŸ“ˆ åŠ¨æ€è°ƒæ•´åçš„ç±»åˆ«æƒé‡:", class_weights.cpu().numpy())

    # === 5. åˆ›å»ºæ¨¡å‹ ===
    def create_optimized_model(model_size='base', num_classes=7, weights_dir='./weights'):
        """åˆ›å»ºä¼˜åŒ–æ¨¡å‹"""
        model_configs = {
            'base': {
                'name': 'vit_base_patch16_224',
                'local_file': 'vit_base_patch16_224.pth',
            }
        }

        config = model_configs[model_size]
        local_weight_path = os.path.join(weights_dir, config['local_file'])

        if not os.path.exists(local_weight_path):
            raise FileNotFoundError(f"âŒ æœªæ‰¾åˆ°æƒé‡æ–‡ä»¶: {local_weight_path}")

        print(f"ğŸ”„ ä»æœ¬åœ°åŠ è½½é¢„è®­ç»ƒæƒé‡: {local_weight_path}")

        # åˆ›å»ºæ¨¡å‹
        model = timm.create_model(config['name'], pretrained=False, num_classes=num_classes)

        try:
            checkpoint = torch.load(local_weight_path, map_location='cpu')
            state_dict = checkpoint
            
            if 'model_state_dict' in state_dict:
                state_dict = state_dict['model_state_dict']
            elif 'state_dict' in state_dict:
                state_dict = state_dict['state_dict']
            elif 'model' in state_dict:
                state_dict = state_dict['model']

            # è¿‡æ»¤åˆ†ç±»å¤´æƒé‡
            filtered_state_dict = {}
            for key, value in state_dict.items():
                if not key.startswith('head.') and not key.startswith('fc.'):
                    filtered_state_dict[key] = value

            # åŠ è½½æƒé‡
            missing_keys, unexpected_keys = model.load_state_dict(filtered_state_dict, strict=False)
            
            print("âœ… é¢„è®­ç»ƒæƒé‡åŠ è½½æˆåŠŸ")
            print(f"  ç¼ºå¤±çš„é”®: {len(missing_keys)}ä¸ª, æ„å¤–çš„é”®: {len(unexpected_keys)}ä¸ª")

        except Exception as e:
            print(f"âŒ æƒé‡åŠ è½½å¤±è´¥: {e}")
            print("ğŸ”„ ä½¿ç”¨éšæœºåˆå§‹åŒ–æ¨¡å‹...")

        return model

    # åˆ›å»ºæ¨¡å‹
    num_classes = 7
    model = create_optimized_model(MODEL_SIZE, num_classes=num_classes)
    model = model.to(device)
    print("âœ… æ¨¡å‹åˆ›å»ºæˆåŠŸ")

    # === 6. è‡ªé€‚åº”ä¼˜åŒ–å™¨é…ç½® ===
    # è§£å†»æ›´å¤šå±‚è¿›è¡Œå¾®è°ƒ
    for name, param in model.named_parameters():
        if 'blocks' in name and int(name.split('.')[1]) >= 8:  # æœ€å4å±‚
            param.requires_grad = True
        if 'head' in name:  # åˆ†ç±»å¤´å§‹ç»ˆè®­ç»ƒ
            param.requires_grad = True

    optimizer = torch.optim.AdamW(
        model.parameters(),
        lr=config['learning_rate'],
        weight_decay=config['weight_decay']
    )
    
    # å­¦ä¹ ç‡è°ƒåº¦
    num_training_steps = len(train_loader) * config['num_epochs'] // config['grad_accum_steps']
    num_warmup_steps = len(train_loader) * config['warmup_epochs'] // config['grad_accum_steps']
    scheduler = get_cosine_schedule_with_warmup(optimizer, num_warmup_steps, num_training_steps)

    # è‡ªé€‚åº”æŸå¤±å‡½æ•°
    class AdaptiveCriterion:
        def __init__(self, class_weights, label_smoothing=0.1):
            self.class_weights = class_weights
            self.label_smoothing = label_smoothing
            self.ce_loss = LabelSmoothingCrossEntropy(smoothing=label_smoothing)
            self.focal_loss = FocalLoss(gamma=2)
            
        def __call__(self, outputs, targets, augmentation_type='none'):
            # åŸºç¡€æŸå¤±
            if augmentation_type == 'cutmix':
                base_loss = self.ce_loss(outputs, targets)
            elif augmentation_type == 'mixup':
                base_loss = self.ce_loss(outputs, targets)
            else:
                base_loss = self.ce_loss(outputs, targets)
            
            # ä¸ºå›°éš¾ç±»åˆ«æ·»åŠ Focal Loss
            disgust_mask = targets == 1
            fear_mask = targets == 2
            
            if disgust_mask.any() or fear_mask.any():
                focal_weight = 0.3  # Focal Lossæƒé‡
                focal_component = self.focal_loss(outputs, targets)
                total_loss = (1 - focal_weight) * base_loss + focal_weight * focal_component
            else:
                total_loss = base_loss
                
            return total_loss

    criterion = AdaptiveCriterion(class_weights, label_smoothing=config['label_smoothing'])

    # æ—©åœæœºåˆ¶
    early_stopping = EarlyStopping(patience=12, delta=0.002, min_epochs=20)

    # è‡ªé€‚åº”æ•°æ®å¢å¼º
    adaptive_aug = AdaptiveDataAugmentation(cutmix_prob=0.6, mixup_prob=0.4)

    print(f"ğŸ¯ ä¼˜åŒ–é…ç½®:")
    print(f"  å­¦ä¹ ç‡: {config['learning_rate']:.1e}")
    print(f"  CutMixæ¦‚ç‡: {adaptive_aug.cutmix_prob}")
    print(f"  MixUpæ¦‚ç‡: {adaptive_aug.mixup_prob}")
    print(f"  åŠ¨æ€æƒé‡è°ƒæ•´: å·²å¯ç”¨")

    # === 7. è®­ç»ƒå‡½æ•° ===
    def train_epoch(model, train_loader, criterion, optimizer, scheduler, device, 
                   grad_accum_steps=2, epoch=0, class_accuracies=None):
        """è‡ªé€‚åº”è®­ç»ƒå‡½æ•°"""
        model.train()
        total_loss = 0
        optimizer.zero_grad()
        
        # æ›´æ–°å¢å¼ºæ¦‚ç‡
        if class_accuracies is not None:
            adaptive_aug.update_probabilities(class_accuracies)

        for i, (images, labels) in enumerate(tqdm(train_loader, desc=f"Epoch {epoch+1}")):
            images, labels = images.to(device, non_blocking=True), labels.to(device, non_blocking=True)

            # åº”ç”¨è‡ªé€‚åº”å¢å¼º
            aug_images, targets_a, targets_b, lam, aug_type = adaptive_aug.apply_augmentation(images, labels, epoch)

            outputs = model(aug_images)
            
            # æ ¹æ®å¢å¼ºç±»å‹è®¡ç®—æŸå¤±
            if aug_type == 'cutmix':
                loss = cutmix_criterion(criterion, outputs, targets_a, targets_b, lam)
            elif aug_type == 'mixup':
                loss = mixup_criterion(criterion, outputs, targets_a, targets_b, lam)
            else:
                loss = criterion(outputs, labels, aug_type)

            # æ¢¯åº¦ç´¯ç§¯
            loss = loss / grad_accum_steps
            loss.backward()

            if (i + 1) % grad_accum_steps == 0:
                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
                optimizer.step()
                scheduler.step()
                optimizer.zero_grad()

            total_loss += loss.item() * grad_accum_steps

        return total_loss / len(train_loader)

    def evaluate(model, dataloader, criterion):
        """éªŒè¯å‡½æ•°"""
        model.eval()
        correct = 0
        total = 0
        total_loss = 0
        all_preds = []
        all_targets = []
        class_correct = [0] * 7
        class_total = [0] * 7

        with torch.no_grad():
            for images, labels in tqdm(dataloader, desc="éªŒè¯ä¸­", leave=False):
                images, labels = images.to(device), labels.to(device)
                outputs = model(images)
                loss = criterion(outputs, labels)
                total_loss += loss.item()

                _, predicted = torch.max(outputs, 1)
                total += labels.size(0)
                correct += (predicted == labels).sum().item()
                
                # è®¡ç®—æ¯ä¸ªç±»åˆ«çš„å‡†ç¡®ç‡
                for i in range(labels.size(0)):
                    label = labels[i]
                    class_correct[label] += (predicted[i] == label).item()
                    class_total[label] += 1
                
                all_preds.extend(predicted.cpu().numpy())
                all_targets.extend(labels.cpu().numpy())

        acc = correct / total
        avg_loss = total_loss / len(dataloader)
        
        # è®¡ç®—å„ç±»åˆ«å‡†ç¡®ç‡
        class_acc = []
        for i in range(7):
            if class_total[i] > 0:
                class_acc.append(class_correct[i] / class_total[i])
            else:
                class_acc.append(0.0)
                
        return acc, avg_loss, class_acc

    # === 8. åŠ è½½æ£€æŸ¥ç‚¹ ===
    def load_checkpoint(model, optimizer, scheduler, filepath):
        """åŠ è½½æ£€æŸ¥ç‚¹"""
        if os.path.exists(filepath):
            print(f"ğŸ”„ åŠ è½½æ£€æŸ¥ç‚¹: {filepath}")
            checkpoint = torch.load(filepath, map_location=device)
            model.load_state_dict(checkpoint['model_state_dict'])
            optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
            scheduler.load_state_dict(checkpoint['scheduler_state_dict'])
            start_epoch = checkpoint['epoch'] + 1
            best_acc = checkpoint['best_acc']
            return start_epoch, best_acc
        return 0, 0.0

    # å°è¯•åŠ è½½æ£€æŸ¥ç‚¹
    checkpoint_path = 'best_vit_base_fixed.pth'
    start_epoch, best_acc = load_checkpoint(model, optimizer, scheduler, checkpoint_path)
    if start_epoch > 0:
        print(f"âœ… ä»ç¬¬{start_epoch}ä¸ªepochæ¢å¤è®­ç»ƒï¼Œæœ€ä½³å‡†ç¡®ç‡: {best_acc*100:.2f}%")
    else:
        best_acc = 0.6712  # ç¬¬4ä¸ªepochçš„ç»“æœ
        start_epoch = 4
        print(f"ğŸ”„ ä»ç¬¬{start_epoch}ä¸ªepochå¼€å§‹è®­ç»ƒ")

    # === 9. è®­ç»ƒå¾ªç¯ ===
    print(f"\nğŸš€ å¼€å§‹è‡ªé€‚åº”ä¼˜åŒ–è®­ç»ƒ (ä»ç¬¬{start_epoch+1}ä¸ªepochå¼€å§‹)")
    print("=" * 60)

    training_history = {
        'train_loss': [], 'val_acc': [], 'val_loss': [], 'learning_rates': [], 'class_acc': []
    }

    # è®°å½•ç¬¬4ä¸ªepochçš„ç»“æœ
    training_history['val_acc'].extend([0.5697, 0.6421, 0.6567, 0.6712])  # 1-4ä¸ªepochçš„ç»“æœ
    training_history['class_acc'].extend([
        [0.578, 0.000, 0.277, 0.897, 0.775, 0.197, 0.551],  # epoch 1
        [0.475, 0.135, 0.261, 0.837, 0.702, 0.682, 0.810],  # epoch 2
        [0.601, 0.090, 0.451, 0.914, 0.724, 0.455, 0.702],  # epoch 3
        [0.646, 0.072, 0.363, 0.928, 0.727, 0.525, 0.746]   # epoch 4
    ])

    for epoch in range(start_epoch, config['num_epochs']):
        epoch_start = time.time()
        print(f"\nğŸ“Š Epoch [{epoch+1}/{config['num_epochs']}]")

        # ä½¿ç”¨ä¸Šä¸€è½®çš„ç±»åˆ«å‡†ç¡®ç‡æŒ‡å¯¼è®­ç»ƒ
        prev_class_acc = training_history['class_acc'][-1] if training_history['class_acc'] else None

        # è®­ç»ƒ
        train_loss = train_epoch(model, train_loader, criterion, optimizer, scheduler, 
                                device, config['grad_accum_steps'], epoch, prev_class_acc)
        training_history['train_loss'].append(train_loss)

        # éªŒè¯
        val_acc, val_loss, class_acc = evaluate(model, val_loader, criterion)
        training_history['val_acc'].append(val_acc)
        training_history['val_loss'].append(val_loss)
        training_history['class_acc'].append(class_acc)
        training_history['learning_rates'].append(optimizer.param_groups[0]['lr'])

        # æ‰“å°ç»“æœ
        current_lr = optimizer.param_groups[0]['lr']
        epoch_time = time.time() - epoch_start
        
        print(f"ğŸ“ˆ è®­ç»ƒæŸå¤±: {train_loss:.4f}")
        print(f"ğŸ¯ éªŒè¯å‡†ç¡®ç‡: {val_acc*100:.2f}% | éªŒè¯æŸå¤±: {val_loss:.4f}")
        print(f"ğŸ’¡ å­¦ä¹ ç‡: {current_lr:.2e}")
        print(f"â±ï¸  æœ¬è½®è€—æ—¶: {epoch_time:.1f}ç§’")
        
        # æ‰“å°å„ç±»åˆ«å‡†ç¡®ç‡
        print("ğŸ“Š å„ç±»åˆ«å‡†ç¡®ç‡:")
        for i, cls_name in enumerate(val_dataset.classes):
            improvement = class_acc[i] - prev_class_acc[i] if prev_class_acc else 0
            arrow = "â†‘" if improvement > 0 else "â†“" if improvement < 0 else "â†’"
            print(f"  {cls_name}: {class_acc[i]*100:5.1f}% {arrow}")

        # ä¿å­˜æœ€ä½³æ¨¡å‹
        if val_acc > best_acc + 0.001:
            best_acc = val_acc
            best_model_path = f'best_vit_{MODEL_SIZE}_adaptive.pth'
            torch.save({
                'model_state_dict': model.state_dict(),
                'optimizer_state_dict': optimizer.state_dict(),
                'scheduler_state_dict': scheduler.state_dict(),
                'epoch': epoch,
                'best_acc': best_acc,
                'config': config,
                'class_acc': class_acc
            }, best_model_path)
            print(f"ğŸ‰ æ–°çš„æœ€ä½³å‡†ç¡®ç‡: {best_acc*100:.2f}% -> {best_model_path}")

        # æ—©åœæ£€æŸ¥
        if early_stopping(val_acc, epoch):
            print("ğŸ›‘ æ—©åœè§¦å‘ï¼Œè®­ç»ƒç»“æŸ")
            break

        print("-" * 60)

        # æ¯3ä¸ªepochä¿å­˜ä¸€æ¬¡checkpoint
        if (epoch + 1) % 3 == 0:
            checkpoint_path = f'checkpoint_epoch_{epoch+1}.pth'
            torch.save({
                'model_state_dict': model.state_dict(),
                'optimizer_state_dict': optimizer.state_dict(),
                'scheduler_state_dict': scheduler.state_dict(),
                'epoch': epoch,
                'best_acc': best_acc,
                'training_history': training_history,
                'config': config
            }, checkpoint_path)
            print(f"ğŸ’¾ æ£€æŸ¥ç‚¹å·²ä¿å­˜: {checkpoint_path}")

    # === 10. è®­ç»ƒæ€»ç»“ ===
    print("\n" + "=" * 60)
    print("ğŸ¯ è®­ç»ƒæ€»ç»“")
    print("=" * 60)
    print(f"ğŸ“Š æœ€ç»ˆæœ€ä½³å‡†ç¡®ç‡: {best_acc*100:.2f}%")
    print(f"ğŸ’¾ æœ€ä½³æ¨¡å‹: best_vit_{MODEL_SIZE}_adaptive.pth")
    print(f"ğŸ”„ æ€»è®­ç»ƒè½®æ¬¡: {epoch+1}")

    # ç»˜åˆ¶è®­ç»ƒæ›²çº¿
    try:
        import matplotlib.pyplot as plt
        plt.figure(figsize=(15, 5))
        
        plt.subplot(1, 3, 1)
        plt.plot(training_history['train_loss'], label='è®­ç»ƒæŸå¤±')
        plt.plot(training_history['val_loss'], label='éªŒè¯æŸå¤±')
        plt.legend()
        plt.title('æŸå¤±æ›²çº¿')
        
        plt.subplot(1, 3, 2)
        plt.plot(training_history['val_acc'], label='éªŒè¯å‡†ç¡®ç‡', color='green')
        plt.axhline(y=best_acc, color='r', linestyle='--', label=f'æœ€ä½³: {best_acc*100:.1f}%')
        plt.legend()
        plt.title('å‡†ç¡®ç‡æ›²çº¿')
        
        # å„ç±»åˆ«å‡†ç¡®ç‡æ›²çº¿
        plt.subplot(1, 3, 3)
        class_acc_array = np.array(training_history['class_acc'])
        for i, cls_name in enumerate(val_dataset.classes):
            plt.plot(class_acc_array[:, i], label=cls_name, marker='o', markersize=2)
        plt.legend()
        plt.title('å„ç±»åˆ«å‡†ç¡®ç‡æ›²çº¿')
        
        plt.tight_layout()
        plt.savefig('training_curves_adaptive.png', dpi=300, bbox_inches='tight')
        print("ğŸ“ˆ è®­ç»ƒæ›²çº¿å·²ä¿å­˜: training_curves_adaptive.png")
    except:
        print("âš ï¸ æ— æ³•ç»˜åˆ¶è®­ç»ƒæ›²çº¿ï¼Œè¯·å®‰è£…matplotlib")

    # === 11. æœ€ç»ˆéªŒè¯ ===
    print("\nğŸ” æœ€ç»ˆæ¨¡å‹éªŒè¯...")
    try:
        checkpoint = torch.load(f'best_vit_{MODEL_SIZE}_adaptive.pth')
        model.load_state_dict(checkpoint['model_state_dict'])
        final_acc, final_loss, class_acc = evaluate(model, val_loader, criterion)
        
        print(f"âœ… æœ€ç»ˆéªŒè¯å‡†ç¡®ç‡: {final_acc*100:.2f}%")
        
        # åˆ†æå„ç±»åˆ«è¡¨ç°
        print("ğŸ“Š å„ç±»åˆ«æœ€ç»ˆå‡†ç¡®ç‡:")
        for i, cls_name in enumerate(val_dataset.classes):
            print(f"  {cls_name}: {class_acc[i]*100:5.1f}%")
        
        if final_acc >= 0.8:
            print("ğŸ‰ æ­å–œï¼è¾¾åˆ°80%å‡†ç¡®ç‡ç›®æ ‡ï¼")
        elif final_acc >= 0.75:
            print("âœ… ä¼˜ç§€ï¼å‡†ç¡®ç‡ > 75%")
        elif final_acc >= 0.7:
            print("ğŸ“ˆ è‰¯å¥½ï¼å‡†ç¡®ç‡ > 70%")
        else:
            print("âš ï¸ éœ€è¦è¿›ä¸€æ­¥ä¼˜åŒ–")
    except Exception as e:
        print(f"âŒ æœ€ç»ˆéªŒè¯å¤±è´¥: {e}")


if __name__ == '__main__':
    main()