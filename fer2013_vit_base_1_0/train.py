import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import DataLoader
from torchvision import transforms, datasets
import timm
from sklearn.metrics import confusion_matrix, classification_report
import numpy as np
from PIL import Image
from tqdm import tqdm
import time
import os
import math
from sklearn.utils.class_weight import compute_class_weight


# === é«˜çº§ä¼˜åŒ–ç»„ä»¶ ===
class EarlyStopping:
    def __init__(self, patience=10, delta=0.001, min_epochs=20):
        self.patience = patience
        self.delta = delta
        self.min_epochs = min_epochs
        self.best_acc = 0
        self.counter = 0
        self.early_stop = False

    def __call__(self, val_acc, epoch):
        if epoch < self.min_epochs:
            return False
            
        if val_acc > self.best_acc + self.delta:
            self.best_acc = val_acc
            self.counter = 0
        else:
            self.counter += 1
            if self.counter >= self.patience:
                self.early_stop = True
        return self.early_stop


class LabelSmoothingCrossEntropy(nn.Module):
    """æ ‡ç­¾å¹³æ»‘æŸå¤±å‡½æ•°"""
    def __init__(self, smoothing=0.1):
        super().__init__()
        self.smoothing = smoothing

    def forward(self, x, target):
        confidence = 1.0 - self.smoothing
        logprobs = F.log_softmax(x, dim=-1)
        nll_loss = -logprobs.gather(dim=-1, index=target.unsqueeze(1))
        nll_loss = nll_loss.squeeze(1)
        smooth_loss = -logprobs.mean(dim=-1)
        loss = confidence * nll_loss + self.smoothing * smooth_loss
        return loss.mean()


def cutmix_data(x, y, alpha=1.0):
    """CutMixæ•°æ®å¢å¼º"""
    if alpha <= 0:
        return x, y, y, 1.0
        
    # ç”Ÿæˆlambdaå€¼
    lam = np.random.beta(alpha, alpha)
    
    batch_size = x.size()[0]
    index = torch.randperm(batch_size).to(x.device)
    
    # ç”Ÿæˆè£å‰ªåŒºåŸŸ
    bbx1, bby1, bbx2, bby2 = rand_bbox(x.size(), lam)
    x[:, :, bbx1:bbx2, bby1:bby2] = x[index, :, bbx1:bbx2, bby1:bby2]
    
    # è°ƒæ•´lambda
    lam = 1 - ((bbx2 - bbx1) * (bby2 - bby1) / (x.size()[-1] * x.size()[-2]))
    y_a, y_b = y, y[index]
    
    return x, y_a, y_b, lam


def rand_bbox(size, lam):
    """ç”Ÿæˆéšæœºè£å‰ªåŒºåŸŸ"""
    W = size[2]
    H = size[3]
    cut_rat = np.sqrt(1. - lam)
    cut_w = int(W * cut_rat)
    cut_h = int(H * cut_rat)

    # å‡åŒ€åˆ†å¸ƒ
    cx = np.random.randint(W)
    cy = np.random.randint(H)

    bbx1 = np.clip(cx - cut_w // 2, 0, W)
    bby1 = np.clip(cy - cut_h // 2, 0, H)
    bbx2 = np.clip(cx + cut_w // 2, 0, W)
    bby2 = np.clip(cy + cut_h // 2, 0, H)

    return bbx1, bby1, bbx2, bby2


def cutmix_criterion(criterion, pred, y_a, y_b, lam):
    """CutMixæŸå¤±å‡½æ•°"""
    return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)


def get_cosine_schedule_with_warmup(optimizer, num_warmup_steps, num_training_steps, num_cycles=0.5):
    """å¸¦çƒ­èº«çš„ä½™å¼¦é€€ç«è°ƒåº¦å™¨"""
    def lr_lambda(current_step):
        if current_step < num_warmup_steps:
            return float(current_step) / float(max(1, num_warmup_steps))
        progress = float(current_step - num_warmup_steps) / float(max(1, num_training_steps - num_warmup_steps))
        return max(0.0, 0.5 * (1.0 + math.cos(math.pi * float(num_cycles) * 2.0 * progress)))
    
    return torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda)


def main():
    print("å¼€å§‹è¿›å…¥è®­ç»ƒ - ä¿®å¤ç‰ˆ (ç›®æ ‡: 80%å‡†ç¡®ç‡)")
    print("=" * 60)

    # === è®¾å¤‡è®¾ç½® ===
    if torch.cuda.is_available():
        device = torch.device('cuda')
        print(f"âœ… ä½¿ç”¨GPU: {torch.cuda.get_device_name()}")
        print(f"ğŸ’¾ æ˜¾å­˜: {torch.cuda.get_device_properties(0).total_memory / 1024 ** 3:.1f} GB")
        torch.cuda.empty_cache()
    else:
        device = torch.device('cpu')
        print("âš ï¸ æœªå‘ç°GPUï¼Œä½¿ç”¨CPU")

    # === è¶…å‚æ•°é…ç½® ===
    config = {
        'model_size': 'base',
        'batch_size': 16,
        'num_epochs': 100,
        'learning_rate': 5e-5,  # å¢å¤§å­¦ä¹ ç‡
        'weight_decay': 0.05,
        'cutmix_alpha': 1.0,
        'label_smoothing': 0.1,
        'drop_rate': 0.2,
        'grad_accum_steps': 2,  # å‡å°‘ç´¯ç§¯æ­¥æ•°
        'warmup_epochs': 10,    # å»¶é•¿çƒ­èº«æœŸ
    }
    
    MODEL_SIZE = config['model_size']
    print(f"ğŸ¯ ç›®æ ‡: 80%éªŒè¯å‡†ç¡®ç‡ | æ¨¡å‹: ViT-{MODEL_SIZE.capitalize()}")

    # === 1. ä¿®å¤æ•°æ®é¢„å¤„ç† ===
    print("\nğŸ”„ é…ç½®ä¿®å¤ç‰ˆæ•°æ®å¢å¼º...")
    
    # è®­ç»ƒæ—¶ä½¿ç”¨çš„å¢å¼ºtransform (ä¿®å¤ç‰ˆ)
    train_transform = transforms.Compose([
        transforms.Resize((256, 256)),  # å…ˆæ”¾å¤§
        transforms.RandomCrop((224, 224)),  # éšæœºè£å‰ª
        transforms.Grayscale(num_output_channels=3),  # ç°åº¦è½¬3é€šé“
        
        # ç©ºé—´å˜æ¢
        transforms.RandomHorizontalFlip(p=0.5),
        transforms.RandomRotation(degrees=15),
        transforms.RandomAffine(degrees=10, translate=(0.1, 0.1), scale=(0.9, 1.1)),
        
        # é¢œè‰²å˜æ¢
        transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.2),
        
        # è½¬æ¢ä¸ºtensor
        transforms.ToTensor(),
        
        # å½’ä¸€åŒ–
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
        
        # tensorä¸Šçš„å˜æ¢ï¼ˆå¿…é¡»åœ¨ToTensorä¹‹åï¼‰
        transforms.RandomErasing(p=0.3, scale=(0.02, 0.2)),
    ])

    # éªŒè¯é›†transform (ç®€åŒ–ç‰ˆ)
    val_transform = transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.Grayscale(num_output_channels=3),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    ])

    # ç®€å•transformç”¨äºè·å–æ ‡ç­¾
    simple_transform = transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.Grayscale(num_output_channels=3),
        transforms.ToTensor(),
    ])

    # === 2. åŠ è½½æ•°æ®é›† ===
    print("ğŸ“ åŠ è½½æ•°æ®é›†...")
    train_dir = './data/train'
    test_dir = './data/test'

    # æ£€æŸ¥æ•°æ®è·¯å¾„
    if not os.path.exists(train_dir):
        raise FileNotFoundError(f"âŒ è®­ç»ƒæ•°æ®è·¯å¾„ä¸å­˜åœ¨: {train_dir}")
    if not os.path.exists(test_dir):
        raise FileNotFoundError(f"âŒ æµ‹è¯•æ•°æ®è·¯å¾„ä¸å­˜åœ¨: {test_dir}")

    train_dataset_simple = datasets.ImageFolder(train_dir, transform=simple_transform)
    train_dataset = datasets.ImageFolder(train_dir, transform=train_transform)
    val_dataset = datasets.ImageFolder(test_dir, transform=val_transform)

    # è·å–è®­ç»ƒæ ‡ç­¾
    train_labels = [label for _, label in train_dataset_simple]

    print(f"ğŸ“Š æ•°æ®ç»Ÿè®¡:")
    print(f"  è®­ç»ƒæ ·æœ¬: {len(train_dataset)}")
    print(f"  éªŒè¯æ ·æœ¬: {len(val_dataset)}")
    print(f"  ç±»åˆ«æ•°é‡: {len(train_dataset.classes)}")
    print(f"  ç±»åˆ«åç§°: {train_dataset.classes}")

    # æ•°æ®åŠ è½½å™¨
    num_workers = min(4, os.cpu_count())
    train_loader = DataLoader(train_dataset, batch_size=config['batch_size'], shuffle=True,
                              num_workers=num_workers, pin_memory=True, drop_last=True)
    val_loader = DataLoader(val_dataset, batch_size=config['batch_size'], shuffle=False,
                            num_workers=num_workers, pin_memory=True)

    print(f"  Batch Size: {config['batch_size']} (ç´¯ç§¯æ­¥æ•°: {config['grad_accum_steps']})")

    # === 3. è®¡ç®—ç±»åˆ«æƒé‡ (ä¿®å¤ç‰ˆ) ===
    class_weights = compute_class_weight('balanced', classes=np.unique(train_labels), y=train_labels)
    class_weights = torch.tensor(class_weights, dtype=torch.float32).to(device)
    
    # é€‚åº¦å¢å¼ºå›°éš¾ç±»åˆ«çš„æƒé‡ (é¿å…è¿‡åº¦åŠ æƒ)
    class_weights[0] *= 1.5  # angry (åŸ2.0)
    class_weights[1] *= 2.0  # fear (åŸ3.0)
    class_weights[5] *= 1.2  # sad (åŸ1.5)
    
    print("ğŸ“ˆ è°ƒæ•´åçš„ç±»åˆ«æƒé‡:", class_weights.cpu().numpy())

    # === 4. ä¿®å¤æ¨¡å‹åˆ›å»º ===
    def create_fixed_model(model_size='base', num_classes=7, weights_dir='./weights'):
        """ä¿®å¤ç‰ˆæ¨¡å‹åˆ›å»ºå‡½æ•°"""
        model_configs = {
            'base': {
                'name': 'vit_base_patch16_224',
                'local_file': 'vit_base_patch16_224.pth',
            }
        }

        if model_size not in model_configs:
            raise ValueError(f"ä¸æ”¯æŒçš„æ¨¡å‹å¤§å°: {model_size}")

        config = model_configs[model_size]
        local_weight_path = os.path.join(weights_dir, config['local_file'])

        if not os.path.exists(local_weight_path):
            print(f"âš ï¸ æœªæ‰¾åˆ°æœ¬åœ°æƒé‡æ–‡ä»¶: {local_weight_path}")
            print("ğŸ”„ ä½¿ç”¨éšæœºåˆå§‹åŒ–æ¨¡å‹...")
            model = timm.create_model(config['name'], pretrained=False, num_classes=num_classes)
            return model

        print(f"ğŸ”„ ä»æœ¬åœ°åŠ è½½é¢„è®­ç»ƒæƒé‡: {local_weight_path}")

        # åˆ›å»ºåŸºç¡€æ¨¡å‹
        model = timm.create_model(config['name'], pretrained=False, num_classes=num_classes)

        try:
            # åŠ è½½æƒé‡æ–‡ä»¶
            checkpoint = torch.load(local_weight_path, map_location='cpu')
            print(f"âœ… æƒé‡æ–‡ä»¶åŠ è½½æˆåŠŸï¼Œå¤§å°: {os.path.getsize(local_weight_path) / 1024**3:.2f} GB")

            # æå–çŠ¶æ€å­—å…¸
            if isinstance(checkpoint, dict):
                if 'model_state_dict' in checkpoint:
                    state_dict = checkpoint['model_state_dict']
                elif 'state_dict' in checkpoint:
                    state_dict = checkpoint['state_dict']
                elif 'model' in checkpoint:
                    state_dict = checkpoint['model']
                else:
                    state_dict = checkpoint
            else:
                state_dict = checkpoint

            print(f"ğŸ” æƒé‡æ–‡ä»¶åŒ…å«çš„é”®æ•°é‡: {len(state_dict)}")

            # è¿‡æ»¤åˆ†ç±»å¤´æƒé‡
            filtered_state_dict = {}
            for key, value in state_dict.items():
                if not any(key.startswith(prefix) for prefix in ['head.', 'fc.', 'classifier.']):
                    filtered_state_dict[key] = value
                else:
                    print(f"âš ï¸ è·³è¿‡åˆ†ç±»å¤´æƒé‡: {key}")

            print(f"ğŸ” è¿‡æ»¤åä¿ç•™çš„é”®æ•°é‡: {len(filtered_state_dict)}")

            # åŠ è½½æƒé‡
            missing_keys, unexpected_keys = model.load_state_dict(filtered_state_dict, strict=False)
            
            print("âœ… é¢„è®­ç»ƒæƒé‡åŠ è½½æˆåŠŸï¼")
            print(f"ğŸ“Š æƒé‡åŠ è½½æŠ¥å‘Š:")
            print(f"  ç¼ºå¤±çš„é”®: {len(missing_keys)}ä¸ª")
            print(f"  æ„å¤–çš„é”®: {len(unexpected_keys)}ä¸ª")

            # éªŒè¯æƒé‡åŠ è½½
            total_params = sum(p.numel() for p in model.parameters())
            pretrained_params = total_params - sum(p.numel() for n, p in model.named_parameters() 
                                                 if n in missing_keys)
            pretrained_ratio = pretrained_params / total_params
            print(f"ğŸ¯ é¢„è®­ç»ƒå‚æ•°æ¯”ä¾‹: {pretrained_ratio*100:.1f}%")

            if pretrained_ratio < 0.9:
                print("âš ï¸ é¢„è®­ç»ƒæƒé‡åŠ è½½æ¯”ä¾‹è¾ƒä½ï¼Œå»ºè®®æ£€æŸ¥æƒé‡æ–‡ä»¶")

        except Exception as e:
            print(f"âŒ æƒé‡åŠ è½½å¤±è´¥: {e}")
            print("ğŸ”„ ä½¿ç”¨éšæœºåˆå§‹åŒ–æ¨¡å‹...")
            model = timm.create_model(config['name'], pretrained=False, num_classes=num_classes)

        return model

    # åˆ›å»ºæ¨¡å‹
    num_classes = 7
    model = create_fixed_model(MODEL_SIZE, num_classes=num_classes)
    model = model.to(device)
    print("âœ… æ¨¡å‹åˆ›å»ºæˆåŠŸ")

    # === 5. ä¼˜åŒ–å™¨é…ç½® (ä¿®å¤ç‰ˆ) ===
    # ä½¿ç”¨ç»Ÿä¸€å­¦ä¹ ç‡ï¼Œé¿å…åˆ†å±‚å­¦ä¹ ç‡å¯¼è‡´çš„é—®é¢˜
    optimizer = torch.optim.AdamW(
        model.parameters(),
        lr=config['learning_rate'],
        weight_decay=config['weight_decay']
    )
    
    # å­¦ä¹ ç‡è°ƒåº¦
    num_training_steps = len(train_loader) * config['num_epochs'] // config['grad_accum_steps']
    num_warmup_steps = len(train_loader) * config['warmup_epochs'] // config['grad_accum_steps']
    scheduler = get_cosine_schedule_with_warmup(optimizer, num_warmup_steps, num_training_steps)

    # æŸå¤±å‡½æ•° (æ ‡ç­¾å¹³æ»‘)
    criterion = LabelSmoothingCrossEntropy(smoothing=config['label_smoothing'])
    criterion.weight = class_weights

    # æ—©åœæœºåˆ¶
    early_stopping = EarlyStopping(patience=12, delta=0.002, min_epochs=20)

    print(f"ğŸ¯ ä¼˜åŒ–é…ç½®:")
    print(f"  å­¦ä¹ ç‡: {config['learning_rate']:.1e}")
    print(f"  CutMix Alpha: {config['cutmix_alpha']}")
    print(f"  æ ‡ç­¾å¹³æ»‘: {config['label_smoothing']}")
    print(f"  çƒ­èº«è½®æ¬¡: {config['warmup_epochs']}")

    # === 6. è®­ç»ƒå‡½æ•° ===
    def train_epoch(model, train_loader, criterion, optimizer, scheduler, device, grad_accum_steps=2):
        """ä¿®å¤ç‰ˆè®­ç»ƒå‡½æ•°"""
        model.train()
        total_loss = 0
        optimizer.zero_grad()

        for i, (images, labels) in enumerate(tqdm(train_loader, desc="è®­ç»ƒä¸­")):
            images, labels = images.to(device, non_blocking=True), labels.to(device, non_blocking=True)

            # 30%æ¦‚ç‡ä½¿ç”¨CutMix (é™ä½æ¦‚ç‡ï¼Œé¿å…æ—©æœŸè®­ç»ƒä¸ç¨³å®š)
            use_cutmix = np.random.rand() < 0.3
            if use_cutmix and i > 10:  # å‰10ä¸ªbatchä¸ä½¿ç”¨CutMix
                images, targets_a, targets_b, lam = cutmix_data(images, labels, config['cutmix_alpha'])
                outputs = model(images)
                loss = cutmix_criterion(criterion, outputs, targets_a, targets_b, lam)
            else:
                outputs = model(images)
                loss = criterion(outputs, labels)

            # æ¢¯åº¦ç´¯ç§¯
            loss = loss / grad_accum_steps
            loss.backward()

            if (i + 1) % grad_accum_steps == 0:
                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
                optimizer.step()
                scheduler.step()
                optimizer.zero_grad()

            total_loss += loss.item() * grad_accum_steps

        return total_loss / len(train_loader)

    def evaluate(model, dataloader, criterion):
        """éªŒè¯å‡½æ•°"""
        model.eval()
        correct = 0
        total = 0
        total_loss = 0
        all_preds = []
        all_targets = []

        with torch.no_grad():
            for images, labels in tqdm(dataloader, desc="éªŒè¯ä¸­", leave=False):
                images, labels = images.to(device), labels.to(device)
                outputs = model(images)
                loss = criterion(outputs, labels)
                total_loss += loss.item()

                _, predicted = torch.max(outputs, 1)
                total += labels.size(0)
                correct += (predicted == labels).sum().item()
                
                all_preds.extend(predicted.cpu().numpy())
                all_targets.extend(labels.cpu().numpy())

        acc = correct / total
        avg_loss = total_loss / len(dataloader)
        
        # è®¡ç®—å„ç±»åˆ«å‡†ç¡®ç‡
        class_acc = []
        for i in range(len(val_dataset.classes)):
            class_mask = np.array(all_targets) == i
            if class_mask.sum() > 0:
                class_acc.append((np.array(all_preds)[class_mask] == i).mean())
            else:
                class_acc.append(0.0)
                
        return acc, avg_loss, class_acc

    # === 7. æ•°æ®éªŒè¯ ===
    print("\nğŸ” éªŒè¯æ•°æ®åŠ è½½å’Œæ¨¡å‹...")
    
    # éªŒè¯æ•°æ®åŠ è½½
    sample_batch = next(iter(train_loader))
    images, labels = sample_batch
    print(f"âœ… æ•°æ®åŠ è½½éªŒè¯:")
    print(f"  è¾“å…¥å½¢çŠ¶: {images.shape}")
    print(f"  æ ‡ç­¾å½¢çŠ¶: {labels.shape}")
    print(f"  åƒç´ èŒƒå›´: [{images.min():.3f}, {images.max():.3f}]")
    print(f"  å‡å€¼: {images.mean():.3f}, æ ‡å‡†å·®: {images.std():.3f}")
    
    # éªŒè¯æ¨¡å‹å‰å‘ä¼ æ’­
    model.eval()
    with torch.no_grad():
        sample_output = model(images[:2].to(device))  # åªæµ‹è¯•2ä¸ªæ ·æœ¬
        print(f"âœ… æ¨¡å‹å‰å‘éªŒè¯:")
        print(f"  è¾“å‡ºå½¢çŠ¶: {sample_output.shape}")
        print(f"  è¾“å‡ºèŒƒå›´: [{sample_output.min():.3f}, {sample_output.max():.3f}]")

    # === 8. è®­ç»ƒå¾ªç¯ ===
    print(f"\nğŸš€ å¼€å§‹ä¿®å¤ç‰ˆè®­ç»ƒ")
    print("=" * 60)

    best_acc = 0.0
    training_history = {
        'train_loss': [], 'val_acc': [], 'val_loss': [], 'learning_rates': []
    }

    for epoch in range(config['num_epochs']):
        epoch_start = time.time()
        print(f"\nğŸ“Š Epoch [{epoch+1}/{config['num_epochs']}]")

        # è®­ç»ƒ
        train_loss = train_epoch(model, train_loader, criterion, optimizer, scheduler, 
                                device, config['grad_accum_steps'])
        training_history['train_loss'].append(train_loss)

        # éªŒè¯
        val_acc, val_loss, class_acc = evaluate(model, val_loader, criterion)
        training_history['val_acc'].append(val_acc)
        training_history['val_loss'].append(val_loss)
        training_history['learning_rates'].append(optimizer.param_groups[0]['lr'])

        # æ‰“å°ç»“æœ
        current_lr = optimizer.param_groups[0]['lr']
        epoch_time = time.time() - epoch_start
        
        print(f"ğŸ“ˆ è®­ç»ƒæŸå¤±: {train_loss:.4f}")
        print(f"ğŸ¯ éªŒè¯å‡†ç¡®ç‡: {val_acc*100:.2f}% | éªŒè¯æŸå¤±: {val_loss:.4f}")
        print(f"ğŸ’¡ å­¦ä¹ ç‡: {current_lr:.2e}")
        print(f"â±ï¸  æœ¬è½®è€—æ—¶: {epoch_time:.1f}ç§’")
        
        # æ‰“å°å„ç±»åˆ«å‡†ç¡®ç‡
        print("ğŸ“Š å„ç±»åˆ«å‡†ç¡®ç‡:")
        for i, cls_name in enumerate(val_dataset.classes):
            print(f"  {cls_name}: {class_acc[i]*100:5.1f}%")

        # ä¿å­˜æœ€ä½³æ¨¡å‹
        if val_acc > best_acc + 0.001:
            best_acc = val_acc
            best_model_path = f'best_vit_{MODEL_SIZE}_fixed.pth'
            torch.save({
                'model_state_dict': model.state_dict(),
                'optimizer_state_dict': optimizer.state_dict(),
                'scheduler_state_dict': scheduler.state_dict(),
                'epoch': epoch,
                'best_acc': best_acc,
                'config': config
            }, best_model_path)
            print(f"ğŸ‰ æ–°çš„æœ€ä½³å‡†ç¡®ç‡: {best_acc*100:.2f}% -> {best_model_path}")

        # æ—©åœæ£€æŸ¥
        if early_stopping(val_acc, epoch):
            print("ğŸ›‘ æ—©åœè§¦å‘ï¼Œè®­ç»ƒç»“æŸ")
            break

        print("-" * 60)

        # æ¯5ä¸ªepochä¿å­˜ä¸€æ¬¡checkpoint
        if (epoch + 1) % 5 == 0:
            checkpoint_path = f'checkpoint_epoch_{epoch+1}.pth'
            torch.save({
                'model_state_dict': model.state_dict(),
                'optimizer_state_dict': optimizer.state_dict(),
                'scheduler_state_dict': scheduler.state_dict(),
                'epoch': epoch,
                'best_acc': best_acc,
                'training_history': training_history,
                'config': config
            }, checkpoint_path)
            print(f"ğŸ’¾ æ£€æŸ¥ç‚¹å·²ä¿å­˜: {checkpoint_path}")

    # === 9. è®­ç»ƒæ€»ç»“ ===
    print("\n" + "=" * 60)
    print("ğŸ¯ è®­ç»ƒæ€»ç»“")
    print("=" * 60)
    print(f"ğŸ“Š æœ€ç»ˆæœ€ä½³å‡†ç¡®ç‡: {best_acc*100:.2f}%")
    print(f"ğŸ’¾ æœ€ä½³æ¨¡å‹: best_vit_{MODEL_SIZE}_fixed.pth")
    print(f"ğŸ”„ æ€»è®­ç»ƒè½®æ¬¡: {epoch+1}")

    # ç»˜åˆ¶è®­ç»ƒæ›²çº¿
    try:
        import matplotlib.pyplot as plt
        plt.figure(figsize=(12, 4))
        
        plt.subplot(1, 2, 1)
        plt.plot(training_history['train_loss'], label='è®­ç»ƒæŸå¤±')
        plt.plot(training_history['val_loss'], label='éªŒè¯æŸå¤±')
        plt.legend()
        plt.title('æŸå¤±æ›²çº¿')
        
        plt.subplot(1, 2, 2)
        plt.plot(training_history['val_acc'], label='éªŒè¯å‡†ç¡®ç‡', color='green')
        plt.axhline(y=best_acc, color='r', linestyle='--', label=f'æœ€ä½³: {best_acc*100:.1f}%')
        plt.legend()
        plt.title('å‡†ç¡®ç‡æ›²çº¿')
        
        plt.tight_layout()
        plt.savefig('training_curves_fixed.png', dpi=300, bbox_inches='tight')
        print("ğŸ“ˆ è®­ç»ƒæ›²çº¿å·²ä¿å­˜: training_curves_fixed.png")
    except:
        print("âš ï¸ æ— æ³•ç»˜åˆ¶è®­ç»ƒæ›²çº¿ï¼Œè¯·å®‰è£…matplotlib")

    # === 10. æœ€ç»ˆéªŒè¯ ===
    print("\nğŸ” æœ€ç»ˆæ¨¡å‹éªŒè¯...")
    try:
        checkpoint = torch.load(f'best_vit_{MODEL_SIZE}_fixed.pth')
        model.load_state_dict(checkpoint['model_state_dict'])
        final_acc, final_loss, class_acc = evaluate(model, val_loader, criterion)
        
        print(f"âœ… æœ€ç»ˆéªŒè¯å‡†ç¡®ç‡: {final_acc*100:.2f}%")
        if final_acc >= 0.8:
            print("ğŸ‰ æ­å–œï¼è¾¾åˆ°80%å‡†ç¡®ç‡ç›®æ ‡ï¼")
        elif final_acc >= 0.7:
            print("âœ… è‰¯å¥½ï¼å‡†ç¡®ç‡ > 70%")
        elif final_acc >= 0.6:
            print("ğŸ“ˆ ä¸­ç­‰ï¼å‡†ç¡®ç‡ > 60%")
        else:
            print("âš ï¸ éœ€è¦è¿›ä¸€æ­¥ä¼˜åŒ–")
    except Exception as e:
        print(f"âŒ æœ€ç»ˆéªŒè¯å¤±è´¥: {e}")

    # === 11. ç¤ºä¾‹é¢„æµ‹ ===
    def predict_single_image(image_path, model, transform, class_names):
        """å•å›¾é¢„æµ‹å‡½æ•°"""
        model.eval()
        try:
            img = Image.open(image_path).convert('L')  # è½¬ä¸ºç°åº¦
            img = transform(img).unsqueeze(0).to(device)

            with torch.no_grad():
                output = model(img)
                probs = torch.softmax(output, dim=1)
                conf, pred = torch.max(probs, 1)

            label = class_names[pred.item()]
            confidence = conf.item()

            print(f"\nğŸ¯ å•å›¾é¢„æµ‹ç»“æœ:")
            print(f"  å›¾ç‰‡: {os.path.basename(image_path)}")
            print(f"  é¢„æµ‹ç±»åˆ«: {label}")
            print(f"  ç½®ä¿¡åº¦: {confidence:.4f}")
            
            # æ‰“å°æ‰€æœ‰ç±»åˆ«æ¦‚ç‡
            print(f"  æ‰€æœ‰ç±»åˆ«æ¦‚ç‡:")
            for i, cls_name in enumerate(class_names):
                print(f"    {cls_name}: {probs[0][i].item():.4f}")
            
            return label, confidence
        except Exception as e:
            print(f"âŒ é¢„æµ‹å¤±è´¥: {e}")
            return None, None

    # ç¤ºä¾‹é¢„æµ‹
    test_image_path = 'data/test/angry/PrivateTest_3309033.jpg'
    if os.path.exists(test_image_path):
        print("\n" + "=" * 50)
        print("ğŸ” ç¤ºä¾‹é¢„æµ‹")
        print("=" * 50)
        predict_single_image(test_image_path, model, val_transform, val_dataset.classes)
    else:
        # å°è¯•æ‰¾åˆ°ä»»æ„æµ‹è¯•å›¾ç‰‡
        for emotion in val_dataset.classes:
            test_dir = os.path.join('data/test', emotion)
            if os.path.exists(test_dir):
                image_files = [f for f in os.listdir(test_dir) if f.endswith(('.jpg', '.png'))]
                if image_files:
                    test_image_path = os.path.join(test_dir, image_files[0])
                    print("\n" + "=" * 50)
                    print("ğŸ” ç¤ºä¾‹é¢„æµ‹")
                    print("=" * 50)
                    predict_single_image(test_image_path, model, val_transform, val_dataset.classes)
                    break


if __name__ == '__main__':
    main()