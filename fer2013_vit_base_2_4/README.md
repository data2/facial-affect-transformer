æˆ‘çœ‹åˆ°äº†å®Œæ•´çš„ä»£ç ã€‚ç»“åˆä½ çš„è®­ç»ƒæ—¥å¿—å’Œä»£ç ï¼Œæˆ‘æ¥åˆ†ææ ¸å¿ƒé—®é¢˜å¹¶æä¾›å…·ä½“çš„ä¼˜åŒ–æ–¹æ¡ˆï¼š

## ğŸ” **æ ¸å¿ƒé—®é¢˜åˆ†æ**

### **1. å¾®è°ƒç­–ç•¥è¢«é”™è¯¯åº”ç”¨**
```python
# åœ¨train()å‡½æ•°ä¸­ï¼š
if config.start_epoch > 20:  # ä»20è½®ä¹‹åç»§ç»­è®­ç»ƒï¼Œé™ä½å¢å¼ºå¼ºåº¦
    config.cutmix_prob = 0.3  # ä»0.5é™åˆ°0.3 âŒ
    config.mixup_prob = 0.15  # ä»0.3é™åˆ°0.15 âŒ
```

**é—®é¢˜**ï¼šç¬¬29è½®æ¢å¤è®­ç»ƒæ—¶ï¼Œ`start_epoch=28 > 20`ï¼Œæ‰€ä»¥å¢å¼ºæ¦‚ç‡è¢«**é”™è¯¯é™ä½**äº†ï¼

### **2. å¼±å¢å¼ºä»ç„¶å¤ªå¼±**
ä½ çš„`apply_weak_augmentation`åªæ˜¯æ°´å¹³ç¿»è½¬+äº®åº¦è°ƒæ•´ï¼Œæ•ˆæœæ¥è¿‘æ— å¢å¼ºã€‚

### **3. å­¦ä¹ ç‡é™åˆ¶å¤ªæ¿€è¿›**
```python
# é™åˆ¶æœ€å¤§å­¦ä¹ ç‡ä¸è¶…è¿‡2.5e-5 âŒ
for param_group in optimizer.param_groups:
    if param_group['lr'] > 2.5e-5:
        param_group['lr'] = 2.5e-5
```

è¿™é˜»æ­¢äº†å­¦ä¹ ç‡æ­£å¸¸ä¸Šå‡åˆ°4-5e-5ï¼Œå½±å“äº†æ¨¡å‹æ”¶æ•›ã€‚

## ğŸš€ **å…·ä½“ä¿®å¤æ–¹æ¡ˆ**

### **ä¿®å¤1ï¼šç§»é™¤é”™è¯¯çš„å¢å¼ºé™ä½**

```python
# ==================== ä¿®å¤train()å‡½æ•°ä¸­çš„é”™è¯¯ ====================
def train(config):
    # ... å‰é¢çš„ä»£ç ä¸å˜ ...
    
    # ==================== ä¿®å¤ï¼šä¸è¦è‡ªåŠ¨é™ä½å¢å¼ºå¼ºåº¦ ====================
    print("ğŸ”§ åº”ç”¨å¾®è°ƒç­–ç•¥:")
    
    # 1. é™ä½å­¦ä¹ ç‡ä¸Šé™
    if config.learning_rate > 1.5e-5:
        original_lr = config.learning_rate
        config.learning_rate = 1.5e-5
        print(f"  ğŸ“‰ å­¦ä¹ ç‡ä¸Šé™: {original_lr} â†’ {config.learning_rate}")
    
    # 2. å»¶é•¿warmupé˜¶æ®µ
    original_warmup = config.warmup_epochs
    if config.warmup_epochs < 20:
        config.warmup_epochs = 20
        print(f"  ğŸ”„ warmupè½®æ•°: {original_warmup} â†’ {config.warmup_epochs}")
    
    # 3. âŒ ç§»é™¤è¿™æ®µï¼ä¸è¦è‡ªåŠ¨é™ä½å¢å¼ºå¼ºåº¦ âŒ
    # original_cutmix = config.cutmix_prob
    # original_mixup = config.mixup_prob
    # if config.start_epoch > 20:
    #     config.cutmix_prob = 0.3
    #     config.mixup_prob = 0.15
    #     print(f"  ğŸ¨ æ•°æ®å¢å¼ºå¼ºåº¦è°ƒæ•´: CutMix({original_cutmix}â†’{config.cutmix_prob}), "
    #           f"MixUp({original_mixup}â†’{config.mixup_prob})")
    
    # æ”¹ä¸ºï¼šæ˜¾ç¤ºå½“å‰å¢å¼ºè®¾ç½®
    print(f"  ğŸ¨ æ•°æ®å¢å¼ºè®¾ç½®: CutMix({config.cutmix_prob}), MixUp({config.mixup_prob})")
    
    # 4. è°ƒæ•´å­¦ä¹ ç‡å³°å€¼é™åˆ¶ï¼ˆæé«˜ä¸€ç‚¹ï¼‰
    print(f"  âš¡ å­¦ä¹ ç‡å³°å€¼é™åˆ¶: 5.0e-5 â†’ 3.5e-5")
    # ==================== ä¿®å¤ç»“æŸ ====================
```

### **ä¿®å¤2ï¼šå¢å¼ºå¼±å¢å¼ºçš„æ•ˆæœ**

```python
class AdvancedAugmentation:
    # ... å…¶ä»–æ–¹æ³•ä¸å˜ ...
    
    def apply_weak_augmentation(self, images, labels):
        """ä¸­ç­‰å¼ºåº¦å¢å¼ºï¼ˆä¸æ˜¯å¼±å¢å¼ºï¼‰"""
        batch_size = images.size(0)
        
        # ==================== å¢å¼ºæ•ˆæœ ====================
        # 1. éšæœºè£å‰ªï¼ˆä¿æŒä¸è®­ç»ƒtransformä¸€è‡´ï¼‰
        if np.random.rand() < 0.7:
            # æ¨¡æ‹ŸRandomResizedCropæ•ˆæœ
            scale = np.random.uniform(0.85, 1.0)
            H, W = images.shape[2], images.shape[3]
            new_H, new_W = int(H * scale), int(W * scale)
            
            # ç®€å•å®ç°éšæœºè£å‰ª
            top = np.random.randint(0, H - new_H) if H > new_H else 0
            left = np.random.randint(0, W - new_W) if W > new_W else 0
            images = images[:, :, top:top+new_H, left:left+new_W]
            images = F.interpolate(images, size=(H, W), mode='bilinear')
        
        # 2. æ°´å¹³ç¿»è½¬
        if torch.rand(1).item() < 0.5:
            images = torch.flip(images, [3])
        
        # 3. é¢œè‰²æ‰°åŠ¨ï¼ˆå¢å¼ºï¼‰
        brightness = torch.rand(batch_size, 1, 1, 1).to(images.device) * 0.3 + 0.85
        contrast = torch.rand(batch_size, 1, 1, 1).to(images.device) * 0.3 + 0.85
        
        images = images * brightness
        mean = images.mean(dim=[1,2,3], keepdim=True)
        images = (images - mean) * contrast + mean
        images = torch.clamp(images, 0, 1)
        
        # 4. è½»å¾®æ—‹è½¬
        if np.random.rand() < 0.3:
            angle = np.random.uniform(-10, 10)
            images = transforms.functional.rotate(images, angle)
        
        return images, labels, labels, 1.0, 'medium'  # æ”¹åä¸ºmedium
```

### **ä¿®å¤3ï¼šè°ƒæ•´å­¦ä¹ ç‡é™åˆ¶**

```python
def train_epoch(...):
    # ... å‰é¢çš„ä»£ç ä¸å˜ ...
    
    if (batch_idx + 1) % config.grad_accum_steps == 0:
        # Gradient clipping
        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)
        
        # ==================== è°ƒæ•´å­¦ä¹ ç‡é™åˆ¶ ====================
        # æé«˜é™åˆ¶åˆ°3.5e-5ï¼Œè®©å­¦ä¹ ç‡èƒ½æ­£å¸¸ä¸Šå‡
        for param_group in optimizer.param_groups:
            if param_group['lr'] > 3.5e-5:
                param_group['lr'] = 3.5e-5
        # ==================== è°ƒæ•´ç»“æŸ ====================
        
        optimizer.step()
        scheduler.step()
        optimizer.zero_grad()
```

### **ä¿®å¤4ï¼šä¼˜åŒ–Configåˆå§‹åŒ–**

```python
class Config:
    def __init__(self):
        # ... å…¶ä»–é…ç½®ä¸å˜ ...
        
        # è°ƒæ•´å¢å¼ºæ¦‚ç‡ï¼ˆåŸºäºä¹‹å‰çš„åˆ†æï¼‰
        self.cutmix_prob = 0.45  # ä»0.5å¾®è°ƒåˆ°0.45
        self.mixup_prob = 0.25   # ä»0.3å¾®è°ƒåˆ°0.25
        self.cutmix_alpha = 0.7  # ä»0.6æ¢å¤åˆ°0.7
        
        # å¢åŠ æ­£åˆ™åŒ–
        self.drop_rate = 0.3     # ä»0.25æé«˜åˆ°0.3
        
        # è°ƒæ•´å­¦ä¹ ç‡ç­–ç•¥
        self.learning_rate = 1.2e-5  # ç•¥å¾®é™ä½
        self.warmup_epochs = 15      # ä»12å¢åŠ åˆ°15
```

### **ä¿®å¤5ï¼šæ›´æ–°è¿›åº¦æ¡æ˜¾ç¤º**

```python
def train_epoch(...):
    # ... å‰é¢çš„ä»£ç ä¸å˜ ...
    
    # æ›´æ–°aug_statsåˆå§‹åŒ–
    aug_stats = {'cutmix': 0, 'mixup': 0, 'medium': 0}  # å»æ‰noneï¼Œæ”¹ä¸ºmedium
    
    # æ›´æ–°è¿›åº¦æ¡æ˜¾ç¤º
    progress_bar.set_postfix({
        'Loss': f'{avg_loss:.4f}',
        'Acc': f'{accuracy:.2f}%',
        'LR': f'{optimizer.param_groups[0]["lr"]:.2e}',
        'Aug': f"{aug_ratio.get('cutmix','0%')}/{aug_ratio.get('mixup','0%')}/{aug_ratio.get('medium','0%')}"
    })
```

## ğŸ“Š **è°ƒæ•´åçš„é¢„æœŸæ•ˆæœ**

### **å¢å¼ºæ¯”ä¾‹å˜åŒ–ï¼š**
```
ä¹‹å‰ï¼šcutmix=30%, mixup=15%, weak=55% (weakå¤ªå¼±)
ç›®æ ‡ï¼šcutmix=45%, mixup=25%, medium=30% (mediumæ˜¯ä¸­ç­‰å¢å¼º)
```

### **å‡†ç¡®ç‡ç›®æ ‡ï¼š**
- è®­ç»ƒå‡†ç¡®ç‡ï¼šä»81%ç•¥å¾®ä¸‹é™åˆ°78-79%ï¼ˆå¢å¼ºæ›´å¼ºï¼‰
- éªŒè¯å‡†ç¡®ç‡ï¼šä»73%æå‡åˆ°74-75%
- è¿‡æ‹Ÿåˆå·®è·ï¼šä»8%ç¼©å°åˆ°4-5%

### **å„ç±»åˆ«æ”¹è¿›é‡ç‚¹ï¼š**
```python
# åœ¨DynamicWeightAdjusterä¸­å¾®è°ƒç­–ç•¥
# é’ˆå¯¹fearå’Œsadçš„ä¸“é¡¹ä¼˜åŒ–
if i == 2 or i == 5:  # fearå’Œsad
    if current_acc < 0.55:  # é™ä½é˜ˆå€¼åˆ°55%
        if (current_acc - recent_avg) < -0.03:  # ä¸‹é™è¶…è¿‡3%
            new_weights[i] *= 2.5  # æ›´å¤§å¹…å¢åŠ 
        else:
            new_weights[i] *= 1.8  # ä¸­ç­‰å¢åŠ 
    elif current_acc > 0.65:  # è¡¨ç°è¾ƒå¥½æ—¶
        new_weights[i] *= 0.85  # è½»å¾®é™ä½æƒé‡
```

## âœ… **æ‰§è¡Œæ­¥éª¤**

1. **ç«‹å³åº”ç”¨ä¿®å¤**ï¼šä¿®æ”¹ä¸Šè¿°5ä¸ªé—®é¢˜ç‚¹
2. **ä»ç¬¬50è½®æœ€ä½³æ¨¡å‹æ¢å¤**ï¼š
   ```bash
   python train.py --resume best_model_80_target.pth --epoch 50
   ```
3. **ç›‘æ§å…³é”®æŒ‡æ ‡**ï¼š
   - mediumæ¯”ä¾‹ï¼šç›®æ ‡30-40%
   - fear/sadå‡†ç¡®ç‡ï¼šç›®æ ‡60%+
   - éªŒè¯å‡†ç¡®ç‡ï¼šç›®æ ‡74%+

4. **å¦‚æœæ•ˆæœå¥½**ï¼šç»§ç»­è®­ç»ƒåˆ°80è½®å·¦å³
5. **å¦‚æœæ•ˆæœä¸å¥½**ï¼šè€ƒè™‘æ·»åŠ æ›´å¤æ‚çš„fear/sadä¼˜åŒ–ç­–ç•¥

## ğŸ¯ **æ€»ç»“**

ä½ çš„æ¨¡å‹å·²ç»è¾¾åˆ°**73.06%**çš„ä¼˜ç§€æ°´å¹³ï¼Œä¸»è¦é—®é¢˜æ˜¯ï¼š
1. **å¢å¼ºè¢«é”™è¯¯é™ä½**ï¼ˆcutmixä»0.5â†’0.3ï¼‰
2. **å¼±å¢å¼ºå¤ªå¼±**ï¼ˆæ¥è¿‘æ— å¢å¼ºï¼‰
3. **å­¦ä¹ ç‡é™åˆ¶å¤ªä¸¥**ï¼ˆå½±å“æ”¶æ•›ï¼‰

ä¿®å¤è¿™äº›é—®é¢˜åï¼Œ**å¾ˆæœ‰å¸Œæœ›çªç ´74%**ï¼Œå¹¶å‘75%è¿ˆè¿›ã€‚å…ˆä»ç¬¬50è½®çš„æœ€ä½³æ¨¡å‹ç»§ç»­è®­ç»ƒï¼Œåº”ç”¨ä¸Šè¿°ä¿®å¤ï¼Œè§‚å¯Ÿ5-10è½®çš„æ•ˆæœã€‚