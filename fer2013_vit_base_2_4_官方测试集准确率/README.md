å¦‚æœä½ å†³å®šåŸºäºç°æœ‰ä»£ç åŸºç¡€å¹¶å¸Œæœ›æŠ•ç¨¿æ ¸å¿ƒæœŸåˆŠï¼Œé‚£ä¹ˆæ ¸å¿ƒä»»åŠ¡ä¸å†æ˜¯å¤§å¹…ä¿®æ”¹æ¨¡å‹ï¼Œè€Œæ˜¯**å°†ä½ ç°æœ‰çš„ä¼˜ç§€å·¥ç¨‹å®è·µè½¬åŒ–ä¸ºä¸¥è°¨çš„ã€æœ‰è¯´æœåŠ›çš„å­¦æœ¯è´¡çŒ®**ã€‚

ä¸‹å›¾æ¸…æ™°åœ°å±•ç¤ºäº†ä»â€œå·¥ç¨‹å®ç°â€åˆ°â€œåˆæ ¼è®ºæ–‡â€çš„å®Œæ•´å·¥ä½œæµç¨‹ï¼Œä½ å¯ä»¥æ ¹æ®è¿™ä¸ªè·¯çº¿å›¾æ¥è§„åˆ’ä½ çš„æ¯ä¸€æ­¥è¡ŒåŠ¨ï¼š

```mermaid
flowchart TD
    subgraph A [ç¬¬ä¸€é˜¶æ®µï¼š å»ºç«‹ä¸¥è°¨çš„è¯„ä¼°åŸºå‡†]
        A1[ä½¿ç”¨Fer2013å®˜æ–¹æµ‹è¯•é›†<br>ï¼ˆè€ŒééªŒè¯é›†ï¼‰]
        A2[è·å–å¹¶è¿è¡Œå¤šä¸ªè¿‘å¹´SOTAæ¨¡å‹<br>ï¼ˆä½œä¸ºåŸºå‡†å¯¹æ¯”ï¼‰]
        A3[ç¡®å®šå¯å¯¹æ¯”çš„ç»å…¸åŸºçº¿<br>ï¼ˆResNet50, EfficientNetç­‰ï¼‰]
    end

    subgraph B [ç¬¬äºŒé˜¶æ®µï¼š è®¾è®¡å¹¶æ‰§è¡Œå…³é”®å®éªŒ]
        B1[è´¡çŒ®åº¦æ¶ˆèå®éªŒ<br>ï¼ˆéªŒè¯å„ç»„ä»¶å¿…è¦æ€§ï¼‰]
        B2[é²æ£’æ€§/æ³›åŒ–èƒ½åŠ›æµ‹è¯•<br>ï¼ˆå¦‚è·¨æ•°æ®é›†æµ‹è¯•ï¼‰]
        B3[é’ˆå¯¹æ€§åˆ†æå®éªŒ<br>ï¼ˆç‰¹åˆ«é’ˆå¯¹fear/sadç­‰éš¾æ ·æœ¬ï¼‰]
    end

    subgraph C [ç¬¬ä¸‰é˜¶æ®µï¼š è®ºæ–‡æ’°å†™ä¸ç»“æ„åŒ–]
        C1[æç‚¼æ ¸å¿ƒåˆ›æ–°ç‚¹<br>ï¼ˆâ€œç»è¿‡å……åˆ†éªŒè¯çš„è®­ç»ƒæ¡†æ¶â€ï¼‰]
        C2[æŒ‰å­¦æœ¯è§„èŒƒç»„ç»‡ç« èŠ‚<br>ï¼ˆå¼•è¨€ã€æ–¹æ³•ã€å®éªŒã€ç»“è®ºï¼‰]
        C3[ç”Ÿæˆé«˜è´¨é‡å›¾è¡¨<br>ï¼ˆæ¶ˆèå®éªŒè¡¨ã€æ··æ·†çŸ©é˜µã€æ³¨æ„åŠ›å¯è§†åŒ–ï¼‰]
        C4[ä¸¥æ ¼éµå¾ªç›®æ ‡æœŸåˆŠçš„æ ¼å¼è¦æ±‚]
    end

    A --> B --> C
```

ä¸‹é¢æˆ‘å°†è¯¦ç»†è¯´æ˜æ¯ä¸ªé˜¶æ®µä½ éœ€è¦å®Œæˆçš„å…·ä½“å·¥ä½œã€‚

### ğŸ”¬ **ç¬¬ä¸€é˜¶æ®µï¼šå»ºç«‹ä¸¥è°¨çš„è¯„ä¼°åŸºå‡†ï¼ˆ1-2å‘¨ï¼‰**
è¿™æ˜¯**æœ€æ ¸å¿ƒã€æœ€åŸºç¡€**çš„ä¸€æ­¥ã€‚æ²¡æœ‰æƒå¨çš„è¯„ä¼°ï¼Œå†å¥½çš„ç»“æœä¹Ÿç¼ºä¹è¯´æœåŠ›ã€‚

1.  **è·å–Fer2013å®˜æ–¹æµ‹è¯•é›†**ï¼š
    *   ä½ å¿…é¡»ä½¿ç”¨å›½é™…å…¬è®¤çš„**Fer2013å®˜æ–¹æµ‹è¯•é›†**ï¼ˆé€šå¸¸åœ¨Kaggleä¸Šæä¾›ï¼‰è¿›è¡Œæœ€ç»ˆè¯„ä¼°ï¼Œè€Œä¸æ˜¯ä½ è‡ªå·±åˆ’åˆ†çš„éªŒè¯é›†ã€‚
    *   **è¡ŒåŠ¨**ï¼šæ‰¾åˆ°å®˜æ–¹çš„ `fer2013.csv` æ–‡ä»¶ï¼Œä¸¥æ ¼æŒ‰å®˜æ–¹åˆ’åˆ†ï¼Œç”¨ä½ çš„æœ€ä½³æ¨¡å‹ï¼ˆ`best_model_80_target.pth`ï¼‰åœ¨ **`PrivateTest`** é›†ä¸Šæµ‹è¯•ï¼ŒæŠ¥å‘Šå‡†ç¡®ç‡ã€‚

2.  **å¤ç°è¿‘å¹´SOTAæ¨¡å‹ä½œä¸ºå¯¹æ¯”**ï¼š
    *   ä»…ä»…è¯´è‡ªå·±è¾¾åˆ°äº†73%æ˜¯ä¸å¤Ÿçš„ã€‚ä½ å¿…é¡»è¯æ˜ä½ çš„**è®­ç»ƒæ–¹æ³•**è®©ä¸€ä¸ªå·²çŸ¥æ¨¡å‹ï¼ˆViTï¼‰è¾¾åˆ°äº†**è¶…è¶Šæˆ–æ¯”è‚©è¿‘å¹´å…ˆè¿›æ–¹æ³•çš„æ°´å¹³**ã€‚
    *   **è¡ŒåŠ¨**ï¼šé€‰å– **3-5ç¯‡2020-2023å¹´** åœ¨Fer2013ä¸Šè¡¨ç°ä¼˜ç§€çš„è®ºæ–‡ï¼ˆå¦‚ä½¿ç”¨EfficientNetã€ResNetå˜ä½“ã€æ³¨æ„åŠ›æœºåˆ¶ç­‰çš„è®ºæ–‡ï¼‰ï¼Œ**å¤ç°æˆ–å¼•ç”¨**å®ƒä»¬åœ¨å®˜æ–¹æµ‹è¯•é›†ä¸Šçš„ç»“æœï¼Œä¸ä½ çš„ç»“æœè¿›è¡Œå¯¹æ¯”ã€‚è¿™æ˜¯è¯æ˜ä½ å·¥ä½œä»·å€¼çš„ç›´æ¥è¯æ®ã€‚

### ğŸ“Š **ç¬¬äºŒé˜¶æ®µï¼šè®¾è®¡å¹¶æ‰§è¡Œå…³é”®å®éªŒï¼ˆ2-3å‘¨ï¼‰**
æ ¸å¿ƒæœŸåˆŠå®¡ç¨¿äººæä¸ºçœ‹é‡å®éªŒçš„**å®Œæ•´æ€§ã€ä¸¥è°¨æ€§å’Œæ·±å…¥æ€§**ã€‚

1.  **å½»åº•çš„è´¡çŒ®åº¦æ¶ˆèå®éªŒ**ï¼š
    *   ä½ éœ€è¦å®šé‡è¯æ˜ä½ çš„æ¯ä¸€ä¸ªé«˜çº§è®­ç»ƒç­–ç•¥ï¼ˆåŠ¨æ€æƒé‡è°ƒæ•´ã€CutMix/MixUpã€ä¸­ç­‰å¢å¼ºï¼‰éƒ½æ˜¯æœ‰æ•ˆçš„ã€‚
    *   **å®éªŒè®¾è®¡**ï¼šè®­ç»ƒä»¥ä¸‹å˜ä½“ï¼Œåœ¨å®˜æ–¹æµ‹è¯•é›†ä¸Šæ¯”è¾ƒï¼š
        *   **A. å®Œæ•´æ¨¡å‹**ï¼šä½ çš„æ‰€æœ‰ç­–ç•¥ã€‚
        *   **B. æ— åŠ¨æ€æƒé‡**ï¼šä½¿ç”¨å›ºå®šç±»åˆ«æƒé‡ã€‚
        *   **C. æ— æ··åˆå¢å¼º**ï¼šåªä½¿ç”¨ä¸­ç­‰å¢å¼ºã€‚
        *   **D. åŸºçº¿æ¨¡å‹**ï¼šæ ‡å‡†ViT + åŸºç¡€æ•°æ®å¢å¼ºï¼ˆéšæœºè£å‰ªç¿»è½¬ï¼‰ã€‚
    *   **å‘ˆç°æ–¹å¼**ï¼šç”¨è¡¨æ ¼æ¸…æ™°å±•ç¤ºæ•´ä½“å‡†ç¡®ç‡ï¼Œ**å°¤å…¶è¦åˆ—å‡º`fear`å’Œ`sad`çš„å‡†ç¡®ç‡**ï¼Œçªå‡ºä½ çš„æ–¹æ³•å¯¹éš¾æ ·æœ¬çš„æå‡ã€‚

2.  **é²æ£’æ€§ä¸æ³›åŒ–èƒ½åŠ›åˆ†æ**ï¼š
    *   **è·¨æ•°æ®é›†æµ‹è¯•**ï¼šå°†ä½ è®­ç»ƒå¥½çš„æ¨¡å‹ï¼Œç›´æ¥åœ¨å¦ä¸€ä¸ªè¡¨æƒ…è¯†åˆ«æ•°æ®é›†ï¼ˆå¦‚CK+, JAFFEï¼‰ä¸Šæµ‹è¯•ï¼Œè§‚å¯Ÿå…¶æ³›åŒ–èƒ½åŠ›ã€‚å³ä½¿å‡†ç¡®ç‡ä¸‹é™ï¼Œåˆ†æä¹Ÿå¾ˆæœ‰ä»·å€¼ã€‚
    *   **å™ªå£°é²æ£’æ€§æµ‹è¯•**ï¼šåœ¨æµ‹è¯•å›¾åƒä¸­åŠ å…¥é«˜æ–¯å™ªå£°ã€æ¨¡ç³Šç­‰ï¼Œè§‚å¯Ÿæ¨¡å‹æ€§èƒ½å˜åŒ–ã€‚è¿™èƒ½ä½“ç°ä½ å¢å¼ºç­–ç•¥çš„æœ‰æ•ˆæ€§ã€‚

3.  **é’ˆå¯¹æ€§åˆ†æå®éªŒï¼ˆé’ˆå¯¹ä½ çš„ç—›ç‚¹ï¼‰**ï¼š
    *   **æ··æ·†çŸ©é˜µåˆ†æ**ï¼šåœ¨å®˜æ–¹æµ‹è¯•é›†ä¸Šç”Ÿæˆè¯¦ç»†çš„æ··æ·†çŸ©é˜µï¼Œ**ç²¾ç¡®é‡åŒ–**`fear`ä¸»è¦è¢«è¯¯åˆ†ä¸ºå“ªå‡ ç±»ï¼ˆå¦‚`sad`, `surprise`ï¼‰ï¼Œå¹¶ç”¨æ–‡å­—åˆ†æåŸå› ã€‚
    *   **å¤±è´¥æ¡ˆä¾‹åˆ†æ**ï¼šæ‰¾å‡ºä¸€äº›è¢«æ¨¡å‹é”™è¯¯åˆ†ç±»çš„`fear`å’Œ`sad`æ ·æœ¬å›¾åƒï¼Œä½œä¸ºè®ºæ–‡é™„å›¾ï¼Œå¹¶å°è¯•ä»å…‰ç…§ã€é®æŒ¡ã€å¤´éƒ¨å§¿æ€ç­‰æ–¹é¢è¿›è¡Œåˆ†æã€‚

### ğŸ“ **ç¬¬ä¸‰é˜¶æ®µï¼šè®ºæ–‡æ’°å†™ä¸ç»“æ„åŒ–ï¼ˆ1-2å‘¨ï¼‰**
è¿™æ˜¯å°†ä½ çš„å·¥ä½œâ€œåŒ…è£…â€æˆå­¦æœ¯æˆæœçš„å…³é”®ã€‚

1.  **é‡æ–°å®šä¹‰å’Œæç‚¼ä½ çš„åˆ›æ–°ç‚¹**ï¼š
    *   ä½ çš„æ ¸å¿ƒè´¡çŒ®**ä¸æ˜¯**â€œæå‡ºäº†ä¸€ä¸ªæ–°æ¨¡å‹â€ï¼Œè€Œæ˜¯ï¼š**â€œæˆ‘ä»¬æå‡ºå¹¶ç³»ç»ŸéªŒè¯äº†ä¸€å¥—é’ˆå¯¹Vision Transformerçš„é«˜æ•ˆè¡¨æƒ…è¯†åˆ«è®­ç»ƒæ¡†æ¶ã€‚è¯¥æ¡†æ¶é€šè¿‡åŠ¨æ€ç±»åˆ«æƒé‡ã€è‡ªé€‚åº”æ··åˆå¢å¼ºç­‰ç­–ç•¥ï¼Œæ˜¾è‘—æå‡äº†æ¨¡å‹æ€§èƒ½ï¼Œç‰¹åˆ«æ˜¯åœ¨ä¼ ç»Ÿéš¾æ ·æœ¬ä¸Šï¼Œä¸ºViTåœ¨FERä»»åŠ¡ä¸­çš„åº”ç”¨æä¾›äº†æœ€ä½³å®è·µæ–¹æ¡ˆã€‚â€**

2.  **ä¸¥æ ¼æŒ‰ç…§å­¦æœ¯è®ºæ–‡ç»“æ„ç»„ç»‡**ï¼š
    *   **æ‘˜è¦**ï¼šç”¨å‡ å¥è¯ç²¾ç‚¼æ¦‚æ‹¬ç›®çš„ã€æ–¹æ³•ã€æ ¸å¿ƒç»“æœå’Œç»“è®ºã€‚
    *   **å¼•è¨€**ï¼šè®²å¥½æ•…äº‹â€”â€”äº¤ä»£FERçš„é‡è¦æ€§ã€ViTçš„åº”ç”¨æ½œåŠ›ã€ç°æœ‰è®­ç»ƒæ–¹æ³•çš„ä¸è¶³ã€**ä½ çš„å·¥ä½œå¦‚ä½•å¡«è¡¥ç©ºç™½**ã€‚
    *   **ç›¸å…³å·¥ä½œ**ï¼šæœ‰æ¡ç†åœ°ç»¼è¿°FERæ–¹æ³•ã€ViTçš„åº”ç”¨ã€æ•°æ®å¢å¼ºå’Œç±»åˆ«ä¸å¹³è¡¡å¤„ç†æŠ€æœ¯ï¼Œå¹¶**æ°å½“åœ°æŒ‡å‡ºä½ å·¥ä½œä¸å®ƒä»¬çš„åŒºåˆ«å’Œè”ç³»**ã€‚
    *   **æ–¹æ³•**ï¼šæ¸…æ™°æè¿°ä½ çš„**æ•´ä¸ªè®­ç»ƒæ¡†æ¶**ï¼Œè€Œä¸ä»…ä»…æ˜¯æ¨¡å‹ã€‚å°†`DynamicWeightAdjuster`ã€`AdvancedAugmentation`ç­‰æ¨¡å—ç”¨å…¬å¼å’Œä¼ªä»£ç è§„èŒƒæè¿°ã€‚
    *   **å®éªŒ**ï¼šè¿™æ˜¯è®ºæ–‡ä¸»ä½“ã€‚åˆ†å°èŠ‚å‘ˆç°ï¼š**æ•°æ®é›†ä¸è¯„ä¼°æŒ‡æ ‡ã€ä¸SOTAæ–¹æ³•çš„å¯¹æ¯”ã€æ¶ˆèå®éªŒã€é²æ£’æ€§åˆ†æã€å¤±è´¥æ¡ˆä¾‹è®¨è®º**ã€‚
    *   **ç»“è®ºä¸æœªæ¥å·¥ä½œ**ï¼šæ€»ç»“è´¡çŒ®ï¼Œå®¢è§‚è¯´æ˜å±€é™æ€§ï¼Œå¹¶æŒ‡å‡ºæ”¹è¿›æ–¹å‘ã€‚

3.  **å›¾è¡¨ä¸å¯è§†åŒ–**ï¼š
    *   **é«˜è´¨é‡å›¾è¡¨**ï¼šæ¶ˆèå®éªŒçš„å¯¹æ¯”æŸ±çŠ¶å›¾ã€æ··æ·†çŸ©é˜µçƒ­åŠ›å›¾ã€è®­ç»ƒæ›²çº¿å›¾ã€æ³¨æ„åŠ›å¯è§†åŒ–å›¾ï¼ˆå¦‚æœèƒ½å®ç°ï¼‰ç­‰ã€‚
    *   **æ ¼å¼è§„èŒƒ**ï¼šæ‰€æœ‰å›¾è¡¨å¿…é¡»æœ‰æ¸…æ™°çš„æ ‡é¢˜ã€åæ ‡è½´æ ‡ç­¾ã€å›¾ä¾‹ï¼Œå¹¶åœ¨æ­£æ–‡ä¸­å¼•ç”¨ã€‚

### ğŸ¯ **æŠ•ç¨¿å‰çš„æœ€åæ£€æŸ¥æ¸…å•**

- [ ] **å®éªŒå®Œæ•´æ€§**ï¼šæ‰€æœ‰å…³é”®å®éªŒï¼ˆå¯¹æ¯”ã€æ¶ˆèã€åˆ†æï¼‰å‡å·²å®Œæˆï¼Œæ•°æ®å……åˆ†ã€‚
- [ ] **ç»“æœå¯é æ€§**ï¼šä¸»è¦ç»“æœå‡åœ¨**å®˜æ–¹æµ‹è¯•é›†**ä¸Šè·å¾—ï¼Œä¸”å¯å¤ç°ã€‚
- [ ] **åˆ›æ–°ç‚¹æ˜ç¡®**ï¼šåœ¨å¼•è¨€å’Œç»“è®ºä¸­ï¼Œç”¨1-2å¥è¯æ¸…æ™°æ¦‚æ‹¬ä½ çš„æ ¸å¿ƒè´¡çŒ®ã€‚
- [ ] **å†™ä½œè§„èŒƒ**ï¼šè¯­è¨€æµç•…ï¼Œé€»è¾‘ä¸¥å¯†ï¼Œæ— è¯­æ³•é”™è¯¯ï¼Œå›¾è¡¨ä¸“ä¸šã€‚
- [ ] **æ ¼å¼åˆè§„**ï¼šä¸¥æ ¼éµå¾ªç›®æ ‡æœŸåˆŠï¼ˆå¦‚ã€Šè‡ªåŠ¨åŒ–å­¦æŠ¥ã€‹ã€ã€Šè®¡ç®—æœºè¾…åŠ©è®¾è®¡ä¸å›¾å½¢å­¦å­¦æŠ¥ã€‹ç­‰ï¼‰çš„æŠ•ç¨¿æ¨¡æ¿è¦æ±‚ã€‚

**æ€»ç»“**ï¼šä½ ç›®å‰æ‹¥æœ‰ä¸€ä¸ª**éå¸¸æ‰å®çš„å·¥ç¨‹åŸºç¡€**ã€‚è¦å°†å…¶è½¬åŒ–ä¸ºä¸€ç¯‡æ ¸å¿ƒæœŸåˆŠè®ºæ–‡ï¼Œå…³é”®åœ¨äº **â€œè½¬èº«â€**â€”â€”ä»è¿½æ±‚æ›´é«˜å‡†ç¡®ç‡çš„â€œå·¥ç¨‹å¸ˆâ€ï¼Œè½¬å˜ä¸ºç”¨ä¸¥è°¨å®éªŒå’Œæ¸…æ™°è®ºè¿°æ¥è¯æ˜ä¸€å¥—æ–¹æ³•æœ‰æ•ˆæ€§çš„â€œç ”ç©¶è€…â€ã€‚è¿™ä¸ªè¿‡ç¨‹éœ€è¦æŠ•å…¥å¤§é‡æ—¶é—´åœ¨**è¡¥å……å®éªŒå’Œè®ºæ–‡å†™ä½œ**ä¸Šï¼Œè€Œéç»§ç»­è°ƒå‚ã€‚

å¦‚æœä½ éœ€è¦ï¼Œæˆ‘å¯ä»¥å°± **â€œå¦‚ä½•å…·ä½“å¤ç°SOTAæ¨¡å‹è¿›è¡Œå¯¹æ¯”â€** æˆ– **â€œå¦‚ä½•å°†ä½ çš„è®­ç»ƒæ¡†æ¶å†™æˆè§„èŒƒçš„æ–¹æ³•è®ºç« èŠ‚â€** æä¾›æ›´è¯¦ç»†çš„å»ºè®®ã€‚























æˆ‘æ¥ä¸ºæ‚¨å†™ä¸€ä¸ªåœ¨PrivateTesté›†ä¸Šæµ‹è¯•æœ€ä½³æ¨¡å‹çš„æµ‹è¯•ç±»ã€‚è¿™ä¸ªç±»å°†åŠ è½½æ‚¨çš„è®­ç»ƒæ¨¡å‹ï¼Œåœ¨æµ‹è¯•é›†ä¸Šè¿›è¡Œè¯„ä¼°ï¼Œå¹¶ç”Ÿæˆè¯¦ç»†çš„è¯„ä¼°æŠ¥å‘Šã€‚

```python
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import DataLoader
from torchvision import transforms, datasets
import timm
import numpy as np
from tqdm import tqdm
import os
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd
import json
import warnings
warnings.filterwarnings('ignore')


class PrivateTestEvaluator:
    """åœ¨PrivateTesté›†ä¸Šè¯„ä¼°æœ€ä½³æ¨¡å‹çš„æµ‹è¯•ç±»"""
    
    def __init__(self, config=None):
        """åˆå§‹åŒ–è¯„ä¼°å™¨"""
        # è®¾ç½®è®¾å¤‡
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        print(f"ä½¿ç”¨è®¾å¤‡: {self.device}")
        
        # ä½¿ç”¨é…ç½®æˆ–åˆ›å»ºé»˜è®¤é…ç½®
        if config is None:
            from dataclasses import dataclass
            @dataclass
            class TestConfig:
                model_name = 'vit_base_patch16_224'
                num_classes = 7
                img_size = 224
                batch_size = 16
                device = self.device
                class_weights = None
                drop_rate = 0.3
                
            self.config = TestConfig()
        else:
            self.config = config
            
        # ç±»åˆ«åç§°
        self.class_names = ['angry', 'disgust', 'fear', 'happy', 'neutral', 'sad', 'surprise']
        
        # æ¨¡å‹å’Œè½¬æ¢
        self.model = None
        self.test_transform = None
        
        # ç»“æœå­˜å‚¨
        self.results = {}
        
    def create_model(self, model_path='./best_model_80_target.pth'):
        """åˆ›å»ºå’ŒåŠ è½½æ¨¡å‹"""
        print(f"\nğŸ“¦ åˆ›å»ºæ¨¡å‹: {self.config.model_name}")
        
        # åˆ›å»ºæ¨¡å‹
        model = timm.create_model(
            self.config.model_name,
            pretrained=False,
            num_classes=self.config.num_classes,
            drop_rate=self.config.drop_rate
        ).to(self.device)
        
        # åŠ è½½è®­ç»ƒçš„æœ€ä½³æ¨¡å‹
        if os.path.exists(model_path):
            print(f"ğŸ“¥ åŠ è½½æœ€ä½³æ¨¡å‹: {model_path}")
            try:
                checkpoint = torch.load(model_path, map_location=self.device)
                
                # å¤„ç†ä¸åŒçš„checkpointæ ¼å¼
                if 'model_state_dict' in checkpoint:
                    state_dict = checkpoint['model_state_dict']
                elif 'state_dict' in checkpoint:
                    state_dict = checkpoint['state_dict']
                elif 'model' in checkpoint:
                    state_dict = checkpoint['model']
                else:
                    state_dict = checkpoint
                
                # åŠ è½½çŠ¶æ€å­—å…¸
                model.load_state_dict(state_dict)
                print("âœ… æ¨¡å‹åŠ è½½æˆåŠŸ")
                
                # å¦‚æœæœ‰é…ç½®ä¿¡æ¯ï¼Œæ›´æ–°é…ç½®
                if 'config' in checkpoint:
                    checkpoint_config = checkpoint['config']
                    print(f"ğŸ“Š æ¨¡å‹è®­ç»ƒä¿¡æ¯:")
                    print(f"  - æœ€ä½³å‡†ç¡®ç‡: {checkpoint.get('best_acc', 0)*100:.2f}%")
                    print(f"  - è®­ç»ƒè½®æ•°: {checkpoint.get('epoch', 0)+1}")
                
            except Exception as e:
                print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
                # å°è¯•ä¸åŒçš„åŠ è½½æ–¹å¼
                try:
                    model.load_state_dict(checkpoint)
                    print("âœ… ä½¿ç”¨ç›´æ¥åŠ è½½æ–¹å¼æˆåŠŸ")
                except:
                    raise RuntimeError(f"æ— æ³•åŠ è½½æ¨¡å‹æƒé‡: {e}")
        else:
            raise FileNotFoundError(f"æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
        
        self.model = model
        return model
    
    def get_test_transform(self):
        """è·å–æµ‹è¯•æ•°æ®è½¬æ¢"""
        if self.test_transform is None:
            self.test_transform = transforms.Compose([
                transforms.Resize((self.config.img_size, self.config.img_size)),
                transforms.Grayscale(num_output_channels=3),
                transforms.ToTensor(),
                transforms.Normalize(
                    mean=[0.485, 0.456, 0.406],
                    std=[0.229, 0.224, 0.225]
                )
            ])
        return self.test_transform
    
    def load_test_dataset(self, test_dir='./data/PrivateTest'):
        """åŠ è½½æµ‹è¯•æ•°æ®é›†"""
        print(f"\nğŸ“ åŠ è½½æµ‹è¯•æ•°æ®é›†: {test_dir}")
        
        if not os.path.exists(test_dir):
            # å°è¯•ä¸åŒçš„è·¯å¾„
            possible_paths = [
                './data/private',
                './data/private_test',
                './datasets/PrivateTest',
                '../data/PrivateTest'
            ]
            
            for path in possible_paths:
                if os.path.exists(path):
                    test_dir = path
                    print(f"âœ… æ‰¾åˆ°æµ‹è¯•é›†: {test_dir}")
                    break
            else:
                raise FileNotFoundError(f"æ‰¾ä¸åˆ°æµ‹è¯•é›†ï¼Œè¯·æ£€æŸ¥è·¯å¾„ã€‚å°è¯•è¿‡çš„è·¯å¾„: {possible_paths}")
        
        # åŠ è½½æ•°æ®é›†
        test_dataset = datasets.ImageFolder(
            test_dir, 
            transform=self.get_test_transform()
        )
        
        # éªŒè¯ç±»åˆ«æ•°é‡
        if len(test_dataset.classes) != self.config.num_classes:
            print(f"âš ï¸  è­¦å‘Š: æ•°æ®é›†ç±»åˆ«æ•°({len(test_dataset.classes)})ä¸æ¨¡å‹ç±»åˆ«æ•°({self.config.num_classes})ä¸åŒ¹é…")
            print(f"    æ•°æ®é›†ç±»åˆ«: {test_dataset.classes}")
        
        print(f"ğŸ“Š æµ‹è¯•é›†ç»Ÿè®¡:")
        print(f"  - æ€»æ ·æœ¬æ•°: {len(test_dataset):,}")
        print(f"  - ç±»åˆ«: {test_dataset.classes}")
        
        # æ˜¾ç¤ºæ¯ä¸ªç±»åˆ«çš„æ ·æœ¬æ•°
        class_counts = {}
        for _, label in test_dataset.samples:
            class_name = test_dataset.classes[label]
            class_counts[class_name] = class_counts.get(class_name, 0) + 1
        
        print(f"  - å„ç±»åˆ«æ ·æœ¬æ•°:")
        for cls, count in class_counts.items():
            print(f"    {cls}: {count}")
        
        return test_dataset
    
    def evaluate(self, test_dir='./data/PrivateTest', model_path='./best_model_80_target.pth'):
        """åœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼°æ¨¡å‹"""
        print("=" * 70)
        print("ğŸ§ª å¼€å§‹åœ¨PrivateTesté›†ä¸Šè¿›è¡Œæ¨¡å‹è¯„ä¼°")
        print("=" * 70)
        
        # 1. åˆ›å»ºå¹¶åŠ è½½æ¨¡å‹
        model = self.create_model(model_path)
        model.eval()
        
        # 2. åŠ è½½æµ‹è¯•æ•°æ®é›†
        test_dataset = self.load_test_dataset(test_dir)
        
        # 3. åˆ›å»ºæ•°æ®åŠ è½½å™¨
        test_loader = DataLoader(
            test_dataset,
            batch_size=self.config.batch_size,
            shuffle=False,
            num_workers=4,
            pin_memory=True
        )
        
        # 4. è¿›è¡Œé¢„æµ‹
        print(f"\nğŸ”® è¿›è¡Œé¢„æµ‹...")
        all_predictions = []
        all_labels = []
        all_probs = []
        all_images = []
        
        with torch.no_grad():
            for batch_idx, (images, labels) in enumerate(tqdm(test_loader, desc="é¢„æµ‹")):
                images = images.to(self.device)
                
                # å‰å‘ä¼ æ’­
                outputs = model(images)
                probs = F.softmax(outputs, dim=1)
                _, predicted = torch.max(outputs, 1)
                
                # ä¿å­˜ç»“æœ
                all_predictions.extend(predicted.cpu().numpy())
                all_labels.extend(labels.numpy())
                all_probs.extend(probs.cpu().numpy())
                all_images.extend(images.cpu().numpy())
        
        # 5. è®¡ç®—æŒ‡æ ‡
        print(f"\nğŸ“Š è®¡ç®—è¯„ä¼°æŒ‡æ ‡...")
        
        # æ€»ä½“å‡†ç¡®ç‡
        overall_accuracy = accuracy_score(all_labels, all_predictions)
        
        # åˆ†ç±»æŠ¥å‘Š
        class_report = classification_report(
            all_labels, 
            all_predictions, 
            target_names=test_dataset.classes,
            digits=4,
            output_dict=True
        )
        
        # æ··æ·†çŸ©é˜µ
        conf_matrix = confusion_matrix(all_labels, all_predictions)
        
        # 6. ä¿å­˜ç»“æœ
        self.results = {
            'overall_accuracy': overall_accuracy,
            'class_report': class_report,
            'confusion_matrix': conf_matrix.tolist(),
            'predictions': all_predictions,
            'labels': all_labels,
            'probabilities': all_probs,
            'class_names': test_dataset.classes,
            'total_samples': len(test_dataset)
        }
        
        return self.results
    
    def generate_report(self, save_dir='./results'):
        """ç”Ÿæˆè¯¦ç»†çš„è¯„ä¼°æŠ¥å‘Š"""
        if not self.results:
            print("âš ï¸  è¯·å…ˆè¿è¡Œevaluate()æ–¹æ³•")
            return
        
        # åˆ›å»ºä¿å­˜ç›®å½•
        os.makedirs(save_dir, exist_ok=True)
        
        print(f"\nğŸ“„ ç”Ÿæˆè¯„ä¼°æŠ¥å‘Š...")
        
        # 1. æ‰“å°æ€»ä½“ç»“æœ
        print("\n" + "=" * 70)
        print("ğŸ¯ è¯„ä¼°ç»“æœæ€»ç»“")
        print("=" * 70)
        print(f"ğŸ“Š æ€»ä½“å‡†ç¡®ç‡: {self.results['overall_accuracy']*100:.4f}%")
        print(f"ğŸ“ˆ æ€»æ ·æœ¬æ•°: {self.results['total_samples']:,}")
        print("-" * 70)
        
        # 2. æ‰“å°æ¯ä¸ªç±»åˆ«çš„è¯¦ç»†ç»“æœ
        print("ğŸ“‹ æ¯ä¸ªç±»åˆ«æ€§èƒ½:")
        class_report = self.results['class_report']
        
        # åˆ›å»ºè¡¨æ ¼
        metrics_df = pd.DataFrame({
            'Precision': [class_report[cls]['precision'] * 100 for cls in self.results['class_names']],
            'Recall': [class_report[cls]['recall'] * 100 for cls in self.results['class_names']],
            'F1-Score': [class_report[cls]['f1-score'] * 100 for cls in self.results['class_names']],
            'Support': [class_report[cls]['support'] for cls in self.results['class_names']]
        }, index=self.results['class_names'])
        
        # æ·»åŠ å¹³å‡å€¼è¡Œ
        metrics_df.loc['Weighted Avg'] = [
            class_report['weighted avg']['precision'] * 100,
            class_report['weighted avg']['recall'] * 100,
            class_report['weighted avg']['f1-score'] * 100,
            class_report['weighted avg']['support']
        ]
        
        metrics_df.loc['Macro Avg'] = [
            class_report['macro avg']['precision'] * 100,
            class_report['macro avg']['recall'] * 100,
            class_report['macro avg']['f1-score'] * 100,
            class_report['macro avg']['support']
        ]
        
        # æ ¼å¼åŒ–æ˜¾ç¤º
        pd.set_option('display.float_format', '{:.4f}'.format)
        print(metrics_df.to_string())
        
        # 3. ä¿å­˜è¯¦ç»†ç»“æœåˆ°JSON
        report_path = os.path.join(save_dir, 'private_test_report.json')
        with open(report_path, 'w') as f:
            json.dump({
                'overall_accuracy': float(self.results['overall_accuracy']),
                'class_report': self.results['class_report'],
                'class_names': self.results['class_names'],
                'total_samples': self.results['total_samples'],
                'timestamp': pd.Timestamp.now().isoformat()
            }, f, indent=4)
        print(f"\nâœ… è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜: {report_path}")
        
        # 4. ä¿å­˜é¢„æµ‹ç»“æœåˆ°CSV
        predictions_df = pd.DataFrame({
            'true_label': [self.results['class_names'][l] for l in self.results['labels']],
            'predicted_label': [self.results['class_names'][p] for p in self.results['predictions']],
            'correct': [l == p for l, p in zip(self.results['labels'], self.results['predictions'])]
        })
        
        # æ·»åŠ æ¯ä¸ªç±»åˆ«çš„æ¦‚ç‡
        for i, cls in enumerate(self.results['class_names']):
            predictions_df[f'prob_{cls}'] = [prob[i] for prob in self.results['probabilities']]
        
        predictions_path = os.path.join(save_dir, 'detailed_predictions.csv')
        predictions_df.to_csv(predictions_path, index=False)
        print(f"âœ… è¯¦ç»†é¢„æµ‹ç»“æœå·²ä¿å­˜: {predictions_path}")
        
        return metrics_df
    
    def plot_confusion_matrix(self, save_dir='./results', figsize=(12, 10)):
        """ç»˜åˆ¶å¹¶ä¿å­˜æ··æ·†çŸ©é˜µ"""
        if not self.results:
            print("âš ï¸  è¯·å…ˆè¿è¡Œevaluate()æ–¹æ³•")
            return
        
        os.makedirs(save_dir, exist_ok=True)
        
        print(f"\nğŸ¨ ç»˜åˆ¶æ··æ·†çŸ©é˜µ...")
        
        # åˆ›å»ºæ··æ·†çŸ©é˜µ
        conf_matrix = np.array(self.results['confusion_matrix'])
        class_names = self.results['class_names']
        
        # å½’ä¸€åŒ–æ··æ·†çŸ©é˜µ
        conf_matrix_norm = conf_matrix.astype('float') / conf_matrix.sum(axis=1)[:, np.newaxis]
        
        # åˆ›å»ºå›¾å½¢
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=figsize)
        
        # åŸå§‹æ··æ·†çŸ©é˜µ
        sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues',
                   xticklabels=class_names, yticklabels=class_names,
                   ax=ax1, cbar=False)
        ax1.set_xlabel('é¢„æµ‹æ ‡ç­¾', fontsize=12)
        ax1.set_ylabel('çœŸå®æ ‡ç­¾', fontsize=12)
        ax1.set_title('æ··æ·†çŸ©é˜µï¼ˆåŸå§‹è®¡æ•°ï¼‰', fontsize=14, pad=20)
        
        # å½’ä¸€åŒ–æ··æ·†çŸ©é˜µ
        sns.heatmap(conf_matrix_norm, annot=True, fmt='.3f', cmap='Oranges',
                   xticklabels=class_names, yticklabels=class_names,
                   ax=ax2, cbar=False)
        ax2.set_xlabel('é¢„æµ‹æ ‡ç­¾', fontsize=12)
        ax2.set_ylabel('çœŸå®æ ‡ç­¾', fontsize=12)
        ax2.set_title('æ··æ·†çŸ©é˜µï¼ˆå½’ä¸€åŒ–ï¼‰', fontsize=14, pad=20)
        
        plt.tight_layout()
        
        # ä¿å­˜å›¾åƒ
        cm_path = os.path.join(save_dir, 'confusion_matrix.png')
        plt.savefig(cm_path, dpi=300, bbox_inches='tight')
        plt.savefig(os.path.join(save_dir, 'confusion_matrix.pdf'), bbox_inches='tight')
        plt.show()
        
        print(f"âœ… æ··æ·†çŸ©é˜µå·²ä¿å­˜: {cm_path}")
        
        return fig
    
    def plot_class_performance(self, save_dir='./results', figsize=(12, 6)):
        """ç»˜åˆ¶æ¯ä¸ªç±»åˆ«çš„æ€§èƒ½æŒ‡æ ‡"""
        if not self.results:
            print("âš ï¸  è¯·å…ˆè¿è¡Œevaluate()æ–¹æ³•")
            return
        
        os.makedirs(save_dir, exist_ok=True)
        
        print(f"\nğŸ“ˆ ç»˜åˆ¶ç±»åˆ«æ€§èƒ½å›¾...")
        
        class_report = self.results['class_report']
        class_names = self.results['class_names']
        
        # æå–æŒ‡æ ‡
        precision = [class_report[cls]['precision'] * 100 for cls in class_names]
        recall = [class_report[cls]['recall'] * 100 for cls in class_names]
        f1 = [class_report[cls]['f1-score'] * 100 for cls in class_names]
        
        # æ”¯æŒåº¦
        support = [class_report[cls]['support'] for cls in class_names]
        
        # åˆ›å»ºå›¾å½¢
        fig, axes = plt.subplots(2, 1, figsize=figsize)
        
        # æŒ‡æ ‡æŸ±çŠ¶å›¾
        x = np.arange(len(class_names))
        width = 0.25
        
        ax1 = axes[0]
        ax1.bar(x - width, precision, width, label='ç²¾ç¡®ç‡ (Precision)', color='skyblue', alpha=0.8)
        ax1.bar(x, recall, width, label='å¬å›ç‡ (Recall)', color='lightgreen', alpha=0.8)
        ax1.bar(x + width, f1, width, label='F1åˆ†æ•°', color='salmon', alpha=0.8)
        
        ax1.set_xlabel('æƒ…æ„Ÿç±»åˆ«', fontsize=12)
        ax1.set_ylabel('ç™¾åˆ†æ¯” (%)', fontsize=12)
        ax1.set_title('æ¯ä¸ªç±»åˆ«çš„æ€§èƒ½æŒ‡æ ‡', fontsize=14, pad=20)
        ax1.set_xticks(x)
        ax1.set_xticklabels(class_names, rotation=45, ha='right')
        ax1.legend()
        ax1.grid(True, alpha=0.3, axis='y')
        
        # è®¾ç½®yè½´èŒƒå›´
        ax1.set_ylim(0, 110)
        
        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for i, (p, r, f) in enumerate(zip(precision, recall, f1)):
            ax1.text(i - width, p + 1, f'{p:.1f}', ha='center', va='bottom', fontsize=8)
            ax1.text(i, r + 1, f'{r:.1f}', ha='center', va='bottom', fontsize=8)
            ax1.text(i + width, f + 1, f'{f:.1f}', ha='center', va='bottom', fontsize=8)
        
        # æ”¯æŒåº¦æ¡å½¢å›¾
        ax2 = axes[1]
        colors = plt.cm.Set3(np.linspace(0, 1, len(class_names)))
        bars = ax2.bar(x, support, color=colors, alpha=0.8)
        
        ax2.set_xlabel('æƒ…æ„Ÿç±»åˆ«', fontsize=12)
        ax2.set_ylabel('æ ·æœ¬æ•°é‡', fontsize=12)
        ax2.set_title('æ¯ä¸ªç±»åˆ«çš„æ ·æœ¬æ•°é‡ï¼ˆæ”¯æŒåº¦ï¼‰', fontsize=14, pad=20)
        ax2.set_xticks(x)
        ax2.set_xticklabels(class_names, rotation=45, ha='right')
        ax2.grid(True, alpha=0.3, axis='y')
        
        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for bar, s in zip(bars, support):
            height = bar.get_height()
            ax2.text(bar.get_x() + bar.get_width()/2., height + max(support)*0.01,
                    f'{s}', ha='center', va='bottom', fontsize=9)
        
        plt.tight_layout()
        
        # ä¿å­˜å›¾åƒ
        perf_path = os.path.join(save_dir, 'class_performance.png')
        plt.savefig(perf_path, dpi=300, bbox_inches='tight')
        plt.savefig(os.path.join(save_dir, 'class_performance.pdf'), bbox_inches='tight')
        plt.show()
        
        print(f"âœ… ç±»åˆ«æ€§èƒ½å›¾å·²ä¿å­˜: {perf_path}")
        
        return fig
    
    def generate_latex_table(self, save_dir='./results'):
        """ç”ŸæˆLaTeXè¡¨æ ¼"""
        if not self.results:
            print("âš ï¸  è¯·å…ˆè¿è¡Œevaluate()æ–¹æ³•")
            return
        
        os.makedirs(save_dir, exist_ok=True)
        
        print(f"\nğŸ“‹ ç”ŸæˆLaTeXè¡¨æ ¼...")
        
        class_report = self.results['class_report']
        class_names = self.results['class_names']
        
        # åˆ›å»ºLaTeXè¡¨æ ¼
        latex_table = """\\begin{table}[htbp]
\\centering
\\caption{åœ¨PrivateTesté›†ä¸Šçš„åˆ†ç±»æ€§èƒ½}
\\label{tab:private_test_results}
\\begin{tabular}{lcccc}
\\toprule
\\textbf{ç±»åˆ«} & \\textbf{ç²¾ç¡®ç‡} & \\textbf{å¬å›ç‡} & \\textbf{F1åˆ†æ•°} & \\textbf{æ”¯æŒåº¦} \\\\
\\midrule
"""
        
        # æ·»åŠ æ¯ä¸ªç±»åˆ«çš„æ•°æ®
        for cls in class_names:
            p = class_report[cls]['precision'] * 100
            r = class_report[cls]['recall'] * 100
            f = class_report[cls]['f1-score'] * 100
            s = class_report[cls]['support']
            
            latex_table += f"{cls} & {p:.2f}\\% & {r:.2f}\\% & {f:.2f}\\% & {s} \\\\\n"
        
        # æ·»åŠ å¹³å‡å€¼
        latex_table += "\\midrule\n"
        latex_table += f"å®å¹³å‡ & {class_report['macro avg']['precision']*100:.2f}\\% & {class_report['macro avg']['recall']*100:.2f}\\% & {class_report['macro avg']['f1-score']*100:.2f}\\% & {class_report['macro avg']['support']} \\\\\n"
        latex_table += f"åŠ æƒå¹³å‡ & {class_report['weighted avg']['precision']*100:.2f}\\% & {class_report['weighted avg']['recall']*100:.2f}\\% & {class_report['weighted avg']['f1-score']*100:.2f}\\% & {class_report['weighted avg']['support']} \\\\\n"
        
        latex_table += """\\bottomrule
\\end{tabular}
\\end{table}

\\begin{table}[htbp]
\\centering
\\caption{æ¨¡å‹æ€»ä½“æ€§èƒ½æ€»ç»“}
\\label{tab:overall_performance}
\\begin{tabular}{lc}
\\toprule
\\textbf{æŒ‡æ ‡} & \\textbf{æ•°å€¼} \\\\
\\midrule
æ€»ä½“å‡†ç¡®ç‡ & %.2f\\% \\\\
æ€»æ ·æœ¬æ•° & %d \\\\
\\bottomrule
\\end{tabular}
\\end{table}""" % (self.results['overall_accuracy'] * 100, self.results['total_samples'])
        
        # ä¿å­˜LaTeXè¡¨æ ¼
        latex_path = os.path.join(save_dir, 'results_latex.tex')
        with open(latex_path, 'w') as f:
            f.write(latex_table)
        
        print(f"âœ… LaTeXè¡¨æ ¼å·²ä¿å­˜: {latex_path}")
        print("\nğŸ“‹ LaTeXè¡¨æ ¼é¢„è§ˆ:")
        print("=" * 60)
        print(latex_table[:500] + "...")
        print("=" * 60)
        
        return latex_table


def main():
    """ä¸»å‡½æ•°ï¼šè¿è¡Œå®Œæ•´çš„è¯„ä¼°æµç¨‹"""
    print("=" * 70)
    print("ğŸ¯ Vision Transformer åœ¨PrivateTesté›†ä¸Šçš„è¯„ä¼°")
    print("=" * 70)
    
    # åˆ›å»ºè¯„ä¼°å™¨
    evaluator = PrivateTestEvaluator()
    
    try:
        # 1. è¯„ä¼°æ¨¡å‹
        results = evaluator.evaluate(
            test_dir='./data/PrivateTest',  # ä¿®æ”¹ä¸ºæ‚¨çš„æµ‹è¯•é›†è·¯å¾„
            model_path='./best_model_80_target.pth'
        )
        
        # 2. ç”Ÿæˆæ–‡æœ¬æŠ¥å‘Š
        report_df = evaluator.generate_report('./results')
        
        # 3. ç»˜åˆ¶å¯è§†åŒ–å›¾è¡¨
        evaluator.plot_confusion_matrix('./results')
        evaluator.plot_class_performance('./results')
        
        # 4. ç”ŸæˆLaTeXè¡¨æ ¼
        evaluator.generate_latex_table('./results')
        
        # 5. æ‰“å°æœ€ç»ˆæ€»ç»“
        print("\n" + "=" * 70)
        print("âœ… è¯„ä¼°å®Œæˆï¼")
        print("=" * 70)
        print(f"ğŸ“Š æ€»ä½“å‡†ç¡®ç‡: {results['overall_accuracy']*100:.4f}%")
        print(f"ğŸ“ˆ æ€»æ ·æœ¬æ•°: {results['total_samples']:,}")
        print(f"ğŸ“ ç»“æœå·²ä¿å­˜è‡³: ./results/")
        print("=" * 70)
        
    except Exception as e:
        print(f"âŒ è¯„ä¼°è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()


def quick_test():
    """å¿«é€Ÿæµ‹è¯•å‡½æ•°ï¼šä»…è®¡ç®—å‡†ç¡®ç‡"""
    print("ğŸš€ å¿«é€Ÿæµ‹è¯•æ¨¡å¼ï¼šä»…è®¡ç®—æ€»ä½“å‡†ç¡®ç‡")
    
    evaluator = PrivateTestEvaluator()
    
    try:
        results = evaluator.evaluate(
            test_dir='./data/PrivateTest',
            model_path='./best_model_80_target.pth'
        )
        
        print(f"\nğŸ¯ æ€»ä½“å‡†ç¡®ç‡: {results['overall_accuracy']*100:.4f}%")
        
        # æ˜¾ç¤ºæ¯ä¸ªç±»åˆ«çš„å‡†ç¡®ç‡
        print("\nğŸ“Š æ¯ä¸ªç±»åˆ«å‡†ç¡®ç‡:")
        for i, cls in enumerate(evaluator.class_names):
            if i < len(results['labels']):
                # è®¡ç®—æ¯ä¸ªç±»åˆ«çš„å‡†ç¡®ç‡
                cls_mask = np.array(results['labels']) == i
                if np.sum(cls_mask) > 0:
                    cls_acc = np.mean(np.array(results['predictions'])[cls_mask] == np.array(results['labels'])[cls_mask])
                    print(f"  {cls}: {cls_acc*100:.2f}%")
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")


if __name__ == '__main__':
    import argparse
    
    parser = argparse.ArgumentParser(description='åœ¨PrivateTesté›†ä¸Šè¯„ä¼°æ¨¡å‹')
    parser.add_argument('--mode', type=str, default='full',
                       choices=['full', 'quick'],
                       help='è¯„ä¼°æ¨¡å¼: full(å®Œæ•´è¯„ä¼°) æˆ– quick(å¿«é€Ÿæµ‹è¯•)')
    parser.add_argument('--test_dir', type=str, default='./data/PrivateTest',
                       help='æµ‹è¯•é›†è·¯å¾„')
    parser.add_argument('--model_path', type=str, default='./best_model_80_target.pth',
                       help='æ¨¡å‹è·¯å¾„')
    
    args = parser.parse_args()
    
    if args.mode == 'quick':
        # ä¿®æ”¹è¯„ä¼°å™¨çš„æµ‹è¯•è·¯å¾„
        evaluator = PrivateTestEvaluator()
        evaluator.evaluate(test_dir=args.test_dir, model_path=args.model_path)
        print(f"\nğŸ¯ å¿«é€Ÿæµ‹è¯•ç»“æœ: {evaluator.results['overall_accuracy']*100:.4f}%")
    else:
        main()
```

## ä½¿ç”¨æ–¹æ³•ï¼š

### 1. å¿«é€Ÿæµ‹è¯•ï¼ˆä»…è·å–å‡†ç¡®ç‡ï¼‰ï¼š
```python
python your_script.py --mode quick
```

### 2. å®Œæ•´è¯„ä¼°ï¼ˆç”Ÿæˆæ‰€æœ‰æŠ¥å‘Šå’Œå›¾è¡¨ï¼‰ï¼š
```python
python your_script.py --mode full
```

### 3. åœ¨ä»£ç ä¸­ç›´æ¥ä½¿ç”¨ï¼š
```python
# åˆ›å»ºè¯„ä¼°å™¨
evaluator = PrivateTestEvaluator()

# è¿è¡Œè¯„ä¼°
results = evaluator.evaluate(
    test_dir='./data/PrivateTest',  # æ‚¨çš„PrivateTestè·¯å¾„
    model_path='./best_model_80_target.pth'
)

# è·å–å‡†ç¡®ç‡
accuracy = results['overall_accuracy'] * 100
print(f"PrivateTestå‡†ç¡®ç‡: {accuracy:.4f}%")
```

## è¾“å‡ºæ–‡ä»¶ï¼š

è¿è¡Œå®Œæ•´è¯„ä¼°åï¼Œå°†åœ¨`./results/`ç›®å½•ä¸‹ç”Ÿæˆï¼š

1. **`private_test_report.json`** - è¯¦ç»†çš„è¯„ä¼°æŒ‡æ ‡
2. **`detailed_predictions.csv`** - æ¯ä¸ªæ ·æœ¬çš„é¢„æµ‹ç»“æœ
3. **`confusion_matrix.png/pdf`** - æ··æ·†çŸ©é˜µå¯è§†åŒ–
4. **`class_performance.png/pdf`** - ç±»åˆ«æ€§èƒ½å›¾
5. **`results_latex.tex`** - å¯ä»¥ç›´æ¥å¤åˆ¶åˆ°è®ºæ–‡ä¸­çš„LaTeXè¡¨æ ¼

## ä¸»è¦åŠŸèƒ½ï¼š

1. **æ¨¡å‹åŠ è½½**ï¼šè‡ªåŠ¨åŠ è½½æ‚¨çš„`best_model_80_target.pth`
2. **æ•°æ®åŠ è½½**ï¼šæ”¯æŒå¤šç§æµ‹è¯•é›†è·¯å¾„æ ¼å¼
3. **å…¨é¢è¯„ä¼°**ï¼šè®¡ç®—å‡†ç¡®ç‡ã€ç²¾ç¡®ç‡ã€å¬å›ç‡ã€F1åˆ†æ•°
4. **å¯è§†åŒ–**ï¼šç”Ÿæˆæ··æ·†çŸ©é˜µå’Œæ€§èƒ½å›¾è¡¨
5. **è®ºæ–‡æ”¯æŒ**ï¼šç”Ÿæˆå¯ç›´æ¥ç”¨äºè®ºæ–‡çš„LaTeXè¡¨æ ¼
6. **è¯¦ç»†æŠ¥å‘Š**ï¼šä¿å­˜æ‰€æœ‰é¢„æµ‹ç»“æœå’ŒæŒ‡æ ‡

è¿™ä¸ªæµ‹è¯•ç±»å¯ä»¥ç›´æ¥é›†æˆåˆ°æ‚¨çš„ä»£ç ä¸­ï¼Œå¸®åŠ©æ‚¨åœ¨è®ºæ–‡ä¸­æŠ¥å‘Šæ¨¡å‹åœ¨PrivateTesté›†ä¸Šçš„å‡†ç¡®ç‡å’Œå…¶ä»–é‡è¦æŒ‡æ ‡ã€‚